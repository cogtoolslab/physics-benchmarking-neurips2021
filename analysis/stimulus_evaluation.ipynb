{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulus evaluation (INTERNAL USE ONLY)\n",
    "We ran a manual check on all the 1200 test stimuli. \n",
    "\n",
    "**The purpose of this notebook is to:** \n",
    "* Fetch the data from mongoDB\n",
    "* Provide summary stats over the number of problematic stim\n",
    "* Display the problematic stims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "sys.path.append('./analysis_helpers')\n",
    "from importlib import reload\n",
    "from analysis_helpers import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(analysis_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(analysis_dir,'utils'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import routines to fetch data from mongoDB**\n",
    "Remember you need to provide `auth.txt` with the password and create the ssh tunnel to the DB instance.\n",
    "Make sure to run `ssh -fNL 27017:127.0.0.1:27017 USERNAME@cogtoolslab.org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ssh -fNL 27017:127.0.0.1:27017 fbinder@cogtoolslab.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fetch the dataframes. This might take a while. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here are the iteration names for the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurips2021_evaluation_iterations = [\n",
    "    {'study': \"dominoes\",\n",
    "     'bucket_name': 'human-physics-benchmarking-dominoes-pilot',\n",
    "     'stim_version': 'production_1',\n",
    "     'iterationName': 'production_1_testing'},\n",
    "    {'study': \"collision\",\n",
    "     'bucket_name': 'human-physics-benchmarking-collision-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "    {'study': \"towers\",\n",
    "     'bucket_name': 'human-physics-benchmarking-towers-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "    {'study': \"linking\",\n",
    "     'bucket_name': 'human-physics-benchmarking-linking-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "    {'study': \"containment\",\n",
    "     'bucket_name': 'human-physics-benchmarking-containment-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "    {'study': \"rollingsliding\",\n",
    "     'bucket_name': 'human-physics-benchmarking-rollingsliding-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "    {'study': \"drop\",\n",
    "     'bucket_name': 'human-physics-benchmarking-drop-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "    {'study': \"clothiness\",\n",
    "     'bucket_name': 'human-physics-benchmarking-clothiness-pilot',\n",
    "     'stim_version': 'production_2',\n",
    "     'iterationName': 'production_2_testing'},\n",
    "]\n",
    "\n",
    "database_name = \"curiophysion_stim_validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to make some tea? ü´ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for it in neurips2021_evaluation_iterations:\n",
    "    _it = it\n",
    "    print(\"Fetching:\",it['study'])\n",
    "    dfs[it['study']] = generate_dataframes.pull_straight_df_from_mongo(\n",
    "        it['study'], database_name)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the ratings across scenarios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario,df in dfs.items():\n",
    "    print(scenario)\n",
    "    print(df['response'].value_counts())\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "Let's look at all problematic stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def display_rows(_df):\n",
    "    \"\"\"Expects a dataframe with the colums 'stimulus_name', 'response', 'stim_url'. \n",
    "    Needs to be wrapped in HTML() to display in a notebook\"\"\"\n",
    "    html = \"\"\n",
    "    for i,row in _df.iterrows():\n",
    "        div = \"\"\"\n",
    "<div>\n",
    "<b>Stim name</b>:{}<br>\n",
    "<b>Ratings</b>:{}<br>\n",
    "<b>Outcome</b>:{}<br>\n",
    "<video width=\"40%\" controls>\n",
    "<source src=\"{}\">\n",
    "</video></div>\"\"\".format(row['stimulus_name'],row['response'],row['target_hit_zone_label'],row['stim_url'])\n",
    "        html+=div\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\n",
    "for scenario, df in dfs.items():\n",
    "    html += \"<h1>{}</h1>\".format(scenario)\n",
    "    df_agg = df.groupby(\"stim_ID\").agg({\n",
    "                                                                    'stimulus_name':'first',\n",
    "                                                                    'response':lambda x:str(np.unique(x)),\n",
    "                                                                    'target_hit_zone_label':'first',\n",
    "                                                                    'stim_url':'first'\n",
    "                                                                    })\n",
    "    df_agg = df_agg[~df_agg['response'].isin(\n",
    "        [\"['Fine üëç']\", \"['Fine üëç' 'Fine']\", \"['Fine' 'Fine üëç']\"])]\n",
    "    html += display_rows(df_agg)\n",
    "\n",
    "HTML(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "485befcfdfc6cbc3686511ea83990961fe5dedc3fb1316054ee2ccf541f5ee49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tdw': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
