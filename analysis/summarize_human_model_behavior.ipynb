{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of human and model behavior across physical domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this notebook is to:** \n",
    "* Apply preprocessing to human behavioral data\n",
    "* Visualize distribution and compute summary statistics over **human** physical judgments\n",
    "* Visualize distribution and compute summary statistics over **model** physical judgments\n",
    "* Conduct human-model comparisons\n",
    "* Output CSV that can be re-loaded into R notebook for statistical modeling & fancy visualizations\n",
    "\n",
    "**This notebook depends on:**\n",
    "* Running `./generate_dataframes.py` (INTERNAL USE ONLY)\n",
    "* Running `./upload_results.py` (INTERNAL USE ONLY)\n",
    "* Running `./download_results.py` (PUBLIC USE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:25:58.602229Z",
     "iopub.status.busy": "2021-06-03T22:25:58.601894Z",
     "iopub.status.idle": "2021-06-03T22:26:00.449403Z",
     "shell.execute_reply": "2021-06-03T22:26:00.448677Z",
     "shell.execute_reply.started": "2021-06-03T22:25:58.602146Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "sys.path.append('./analysis_helpers')\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import analysis_helpers as h\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:00.451469Z",
     "iopub.status.busy": "2021-06-03T22:26:00.451110Z",
     "iopub.status.idle": "2021-06-03T22:26:00.455935Z",
     "shell.execute_reply": "2021-06-03T22:26:00.454737Z",
     "shell.execute_reply.started": "2021-06-03T22:26:00.451440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# seaborn plotting themes\n",
    "sns.set_context('talk')\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:00.458097Z",
     "iopub.status.busy": "2021-06-03T22:26:00.457796Z",
     "iopub.status.idle": "2021-06-03T22:26:00.468869Z",
     "shell.execute_reply": "2021-06-03T22:26:00.467896Z",
     "shell.execute_reply.started": "2021-06-03T22:26:00.458070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(analysis_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(analysis_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:00.470590Z",
     "iopub.status.busy": "2021-06-03T22:26:00.470082Z",
     "iopub.status.idle": "2021-06-03T22:26:00.486678Z",
     "shell.execute_reply": "2021-06-03T22:26:00.485915Z",
     "shell.execute_reply.started": "2021-06-03T22:26:00.470553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>bucket_name</th>\n",
       "      <th>stim_version</th>\n",
       "      <th>iterationName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dominoes_pilot</td>\n",
       "      <td>human-physics-benchmarking-dominoes-pilot</td>\n",
       "      <td>production_1</td>\n",
       "      <td>production_1_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collision_pilot</td>\n",
       "      <td>human-physics-benchmarking-collision-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>towers_pilot</td>\n",
       "      <td>human-physics-benchmarking-towers-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linking_pilot</td>\n",
       "      <td>human-physics-benchmarking-linking-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>containment_pilot</td>\n",
       "      <td>human-physics-benchmarking-containment-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rollingsliding_pilot</td>\n",
       "      <td>human-physics-benchmarking-rollingsliding-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drop_pilot</td>\n",
       "      <td>human-physics-benchmarking-drop-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clothiness_pilot</td>\n",
       "      <td>human-physics-benchmarking-clothiness-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  study                                      bucket_name  \\\n",
       "0        dominoes_pilot        human-physics-benchmarking-dominoes-pilot   \n",
       "1       collision_pilot       human-physics-benchmarking-collision-pilot   \n",
       "2          towers_pilot          human-physics-benchmarking-towers-pilot   \n",
       "3         linking_pilot         human-physics-benchmarking-linking-pilot   \n",
       "4     containment_pilot     human-physics-benchmarking-containment-pilot   \n",
       "5  rollingsliding_pilot  human-physics-benchmarking-rollingsliding-pilot   \n",
       "6            drop_pilot            human-physics-benchmarking-drop-pilot   \n",
       "7      clothiness_pilot      human-physics-benchmarking-clothiness-pilot   \n",
       "\n",
       "   stim_version         iterationName  \n",
       "0  production_1  production_1_testing  \n",
       "1  production_2  production_2_testing  \n",
       "2  production_2  production_2_testing  \n",
       "3  production_2  production_2_testing  \n",
       "4  production_2  production_2_testing  \n",
       "5  production_2  production_2_testing  \n",
       "6  production_2  production_2_testing  \n",
       "7  production_2  production_2_testing  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_meta import *\n",
    "HEM = pd.DataFrame(NEURIPS2021_EXPS) # HEM = \"human experiment metadata\"\n",
    "HEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:00.488405Z",
     "iopub.status.busy": "2021-06-03T22:26:00.487990Z",
     "iopub.status.idle": "2021-06-03T22:26:00.493437Z",
     "shell.execute_reply": "2021-06-03T22:26:00.492314Z",
     "shell.execute_reply.started": "2021-06-03T22:26:00.488369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCENARIOS = sorted([n.split(\"_\")[0] for n in HEM['study'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:00.495338Z",
     "iopub.status.busy": "2021-06-03T22:26:00.495150Z",
     "iopub.status.idle": "2021-06-03T22:26:00.501543Z",
     "shell.execute_reply": "2021-06-03T22:26:00.500554Z",
     "shell.execute_reply.started": "2021-06-03T22:26:00.495318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get paths to all human response data\n",
    "data_paths = [os.path.join(csv_dir,'humans',i) for i in os.listdir(os.path.join(csv_dir,'humans'))]\n",
    "resp_paths = [i for i in data_paths if i.split('/')[-1].split('-')[0]=='human_responses']\n",
    "assert len(resp_paths)==8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:00.506552Z",
     "iopub.status.busy": "2021-06-03T22:26:00.506336Z",
     "iopub.status.idle": "2021-06-03T22:26:08.536606Z",
     "shell.execute_reply": "2021-06-03T22:26:08.535938Z",
     "shell.execute_reply.started": "2021-06-03T22:26:00.506533Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105600 lines\n"
     ]
    }
   ],
   "source": [
    "## also load all human data into a big dataframe\n",
    "HD = pd.concat([h.apply_exclusion_criteria(h.load_and_preprocess_data(p)) for p in resp_paths])\n",
    "print(\"Loaded {} lines\".format(len(HD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:08.539900Z",
     "iopub.status.busy": "2021-06-03T22:26:08.539639Z",
     "iopub.status.idle": "2021-06-03T22:26:08.544473Z",
     "shell.execute_reply": "2021-06-03T22:26:08.543451Z",
     "shell.execute_reply.started": "2021-06-03T22:26:08.539864Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get paths to all model data\n",
    "model_data_paths = [os.path.join(csv_dir,'models',i) for i in os.listdir(os.path.join(csv_dir,'models'))]\n",
    "model_res_paths = [i for i in model_data_paths if i.split('.')[-1] == \"csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:08.546629Z",
     "iopub.status.busy": "2021-06-03T22:26:08.546196Z",
     "iopub.status.idle": "2021-06-03T22:26:09.209546Z",
     "shell.execute_reply": "2021-06-03T22:26:09.208690Z",
     "shell.execute_reply.started": "2021-06-03T22:26:08.546604Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 177990 rows\n"
     ]
    }
   ],
   "source": [
    "## load all model results into a single dataframe\n",
    "MD = pd.concat([pd.read_csv(p).assign(filename=p.split('/')[-1]) for p in model_res_paths])\n",
    "print(\"Loaded {} rows\".format(len(MD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:09.210944Z",
     "iopub.status.busy": "2021-06-03T22:26:09.210668Z",
     "iopub.status.idle": "2021-06-03T22:26:11.402474Z",
     "shell.execute_reply": "2021-06-03T22:26:11.401736Z",
     "shell.execute_reply.started": "2021-06-03T22:26:09.210921Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a couple of import steps (restore original scenario names, add single prediction value, add correctness column)\n",
    "MD = h.process_model_dataframe(MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:11.408497Z",
     "iopub.status.busy": "2021-06-03T22:26:11.408216Z",
     "iopub.status.idle": "2021-06-03T22:26:12.268649Z",
     "shell.execute_reply": "2021-06-03T22:26:12.267853Z",
     "shell.execute_reply.started": "2021-06-03T22:26:11.408460Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️There are 0 duplicated rows!\n",
      "Removed duplicates, 177990 rows left\n"
     ]
    }
   ],
   "source": [
    "#check for duplicated rows\n",
    "if len(MD.duplicated()) > 0:\n",
    "    print(\"⚠️There are {} duplicated rows!\".format(np.sum(MD.duplicated())))\n",
    "    MD = MD[~MD.duplicated(h.MODEL_COLS+[\"Stimulus Name\"],keep=\"first\")]\n",
    "    print(\"Removed duplicates, {} rows left\".format(len(MD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.270416Z",
     "iopub.status.busy": "2021-06-03T22:26:12.270092Z",
     "iopub.status.idle": "2021-06-03T22:26:12.291323Z",
     "shell.execute_reply": "2021-06-03T22:26:12.290750Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.270354Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model kinds to variable\n",
    "MODELS = list(MD[\"Model Kind\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.292949Z",
     "iopub.status.busy": "2021-06-03T22:26:12.292584Z",
     "iopub.status.idle": "2021-06-03T22:26:12.299190Z",
     "shell.execute_reply": "2021-06-03T22:26:12.298286Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.292924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get the following kinds of models:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same',\n",
       " 'RPIN_R-CNN_0.0_L2 on 2D position_all_but_this_L2 on 2D position_0_same',\n",
       " 'RPIN_R-CNN_0.0_L2 on 2D position_all_L2 on 2D position_0_same',\n",
       " 'RPIN_R-CNN_0.0_L2 on 2D position_same_L2 on 2D position_0_same',\n",
       " 'RPIN_R-CNN_1.0_L2 on 2D position_all_but_this_L2 on 2D position_1_same',\n",
       " 'RPIN_R-CNN_2.0_L2 on 2D position_all_but_this_L2 on 2D position_2_same',\n",
       " 'RPIN_R-CNN_1.0_L2 on 2D position_all_L2 on 2D position_1_same',\n",
       " 'RPIN_R-CNN_2.0_L2 on 2D position_all_L2 on 2D position_2_same',\n",
       " 'RPIN_R-CNN_1.0_L2 on 2D position_same_L2 on 2D position_1_same',\n",
       " 'RPIN_R-CNN_2.0_L2 on 2D position_same_L2 on 2D position_2_same',\n",
       " 'SVG_VGG_1.0_VAE_all_but_this_VAE_1_same',\n",
       " 'SVG_VGG_1.0_VAE_all_VAE_1_same',\n",
       " 'SVG_VGG_1.0_VAE_same_VAE_1_same',\n",
       " 'VGGFrozenLSTM_VGG_nan_nan_nan_L2 on latent_0_same',\n",
       " 'CSWM_CSWM encoder_0.0_Contrastive_all_but_this_Contrastive_0_same',\n",
       " 'CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_same',\n",
       " 'CSWM_CSWM encoder_0.0_Contrastive_same_Contrastive_0_same',\n",
       " 'DEITFrozenLSTM_DEIT_nan_nan_nan_L2 on latent_0_same',\n",
       " 'DEITFrozenMLP_DEIT_nan_nan_nan_L2 on latent_0_same',\n",
       " 'OP3_OP3 encoder_0.0_Image Reconstruction_all_but_this_Image Reconstruction_0_same',\n",
       " 'OP3_OP3 encoder_0.0_Image Reconstruction_all_Image Reconstruction_0_same',\n",
       " 'OP3_OP3 encoder_0.0_Image Reconstruction_same_Image Reconstruction_0_same']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"We get the following kinds of models:\")\n",
    "display(MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exclude bad stims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.301019Z",
     "iopub.status.busy": "2021-06-03T22:26:12.300639Z",
     "iopub.status.idle": "2021-06-03T22:26:12.345453Z",
     "shell.execute_reply": "2021-06-03T22:26:12.344383Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.300984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 bad stims\n"
     ]
    }
   ],
   "source": [
    "stim_comparision = pd.merge(pd.DataFrame(MD.groupby('Canon Stimulus Name')['Actual Outcome'].first()).reset_index(),pd.DataFrame(HD.groupby('stim_ID')['target_hit_zone_label'].first()).reset_index(),left_on='Canon Stimulus Name',right_on='stim_ID')\n",
    "\n",
    "bad_stims = stim_comparision[stim_comparision['Actual Outcome'] != stim_comparision['target_hit_zone_label']]['Canon Stimulus Name']\n",
    "print(\"There are {} bad stims\".format(len(bad_stims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.346914Z",
     "iopub.status.busy": "2021-06-03T22:26:12.346540Z",
     "iopub.status.idle": "2021-06-03T22:26:12.457733Z",
     "shell.execute_reply": "2021-06-03T22:26:12.457061Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.346844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Exclude bad stims\n",
    "HD = HD[~HD['stim_ID'].isin(bad_stims)]\n",
    "MD = MD[~MD['Canon Stimulus Name'].isin(bad_stims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.459283Z",
     "iopub.status.busy": "2021-06-03T22:26:12.458940Z",
     "iopub.status.idle": "2021-06-03T22:26:12.635888Z",
     "shell.execute_reply": "2021-06-03T22:26:12.635224Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.459240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Also exclude stims from the rollingsliding ledge subset\n",
    "HD = HD[~HD['stim_ID'].str.contains(\"rollingSliding_simple_ledge\")]\n",
    "MD = MD[~MD['Canon Stimulus Name'].str.contains(\"rollingSliding_simple_ledge\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.637696Z",
     "iopub.status.busy": "2021-06-03T22:26:12.637264Z",
     "iopub.status.idle": "2021-06-03T22:26:12.701722Z",
     "shell.execute_reply": "2021-06-03T22:26:12.700986Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.637657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Readout Train Data</th>\n",
       "      <th>Readout Test Data</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Readout Type</th>\n",
       "      <th>Predicted Prob_false</th>\n",
       "      <th>Predicted Prob_true</th>\n",
       "      <th>Predicted Outcome</th>\n",
       "      <th>Actual Outcome</th>\n",
       "      <th>Stimulus Name</th>\n",
       "      <th>Encoder Type</th>\n",
       "      <th>Dynamics Type</th>\n",
       "      <th>Encoder Pre-training Task</th>\n",
       "      <th>Encoder Pre-training Dataset</th>\n",
       "      <th>Encoder Pre-training Seed</th>\n",
       "      <th>Encoder Training Task</th>\n",
       "      <th>Encoder Training Dataset</th>\n",
       "      <th>Encoder Training Seed</th>\n",
       "      <th>Dynamics Training Task</th>\n",
       "      <th>Dynamics Training Dataset</th>\n",
       "      <th>Dynamics Training Seed</th>\n",
       "      <th>filename</th>\n",
       "      <th>correct</th>\n",
       "      <th>Canon Stimulus Name</th>\n",
       "      <th>Encoder Training Dataset Type</th>\n",
       "      <th>Dynamics Training Dataset Type</th>\n",
       "      <th>Readout Train Data Type</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>Model Kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>linking</td>\n",
       "      <td>linking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_linking</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_results.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>linking</td>\n",
       "      <td>linking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>A</td>\n",
       "      <td>1.614928e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_linking</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_results.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>linking</td>\n",
       "      <td>linking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_linking</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_results.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>linking</td>\n",
       "      <td>linking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>A</td>\n",
       "      <td>9.019755e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_linking</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_results.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>linking</td>\n",
       "      <td>linking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>A</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_linking</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_results.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15736</th>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>towers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>C</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.464184e-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_towers_nb2_fr015_SJ010_mono0_dis0_occ0_b...</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_results.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>pilot_towers_nb2_fr015_SJ010_mono0_dis0_occ0_b...</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15737</th>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>towers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>C</td>\n",
       "      <td>3.463896e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_towers_nb4_SJ025_mono1_dis1_occ1_boxroom...</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_results.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>pilot_towers_nb4_SJ025_mono1_dis1_occ1_boxroom...</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>towers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>C</td>\n",
       "      <td>9.975404e-01</td>\n",
       "      <td>2.459590e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_towers_nb3_fr015_SJ025_mono1_dis0_occ0_t...</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_results.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>pilot_towers_nb3_fr015_SJ025_mono1_dis0_occ0_t...</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15739</th>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>towers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>C</td>\n",
       "      <td>1.046119e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_towers_nb5_fr015_SJ030_mono0_dis0_occ0_b...</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_results.csv</td>\n",
       "      <td>True</td>\n",
       "      <td>pilot_towers_nb5_fr015_SJ030_mono0_dis0_occ0_b...</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15740</th>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>towers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479339</td>\n",
       "      <td>C</td>\n",
       "      <td>9.999134e-01</td>\n",
       "      <td>8.660837e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pilot_towers_nb4_fr015_SJ000_gr01_mono1_dis0_o...</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_results.csv</td>\n",
       "      <td>False</td>\n",
       "      <td>pilot_towers_nb4_fr015_SJ000_gr01_mono1_dis0_o...</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171156 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Readout Train Data Readout Test Data  Train Accuracy  \\\n",
       "0      VGGFrozenMLP            linking           linking             1.0   \n",
       "1      VGGFrozenMLP            linking           linking             1.0   \n",
       "2      VGGFrozenMLP            linking           linking             1.0   \n",
       "3      VGGFrozenMLP            linking           linking             1.0   \n",
       "4      VGGFrozenMLP            linking           linking             1.0   \n",
       "...             ...                ...               ...             ...   \n",
       "15736           OP3             towers            towers             1.0   \n",
       "15737           OP3             towers            towers             1.0   \n",
       "15738           OP3             towers            towers             1.0   \n",
       "15739           OP3             towers            towers             1.0   \n",
       "15740           OP3             towers            towers             1.0   \n",
       "\n",
       "       Test Accuracy Readout Type  Predicted Prob_false  Predicted Prob_true  \\\n",
       "0           0.611650            A          0.000000e+00         1.000000e+00   \n",
       "1           0.611650            A          1.614928e-08         1.000000e+00   \n",
       "2           0.611650            A          0.000000e+00         1.000000e+00   \n",
       "3           0.611650            A          9.019755e-08         9.999999e-01   \n",
       "4           0.611650            A          0.000000e+00         1.000000e+00   \n",
       "...              ...          ...                   ...                  ...   \n",
       "15736       0.479339            C          1.000000e+00         6.464184e-11   \n",
       "15737       0.479339            C          3.463896e-14         1.000000e+00   \n",
       "15738       0.479339            C          9.975404e-01         2.459590e-03   \n",
       "15739       0.479339            C          1.046119e-11         1.000000e+00   \n",
       "15740       0.479339            C          9.999134e-01         8.660837e-05   \n",
       "\n",
       "       Predicted Outcome  Actual Outcome  \\\n",
       "0                      1               0   \n",
       "1                      1               0   \n",
       "2                      1               1   \n",
       "3                      1               0   \n",
       "4                      1               1   \n",
       "...                  ...             ...   \n",
       "15736                  0               1   \n",
       "15737                  1               1   \n",
       "15738                  0               1   \n",
       "15739                  1               1   \n",
       "15740                  0               1   \n",
       "\n",
       "                                           Stimulus Name Encoder Type  \\\n",
       "0      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...          VGG   \n",
       "1      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...          VGG   \n",
       "2      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...          VGG   \n",
       "3      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...          VGG   \n",
       "4      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...          VGG   \n",
       "...                                                  ...          ...   \n",
       "15736  pilot_towers_nb2_fr015_SJ010_mono0_dis0_occ0_b...  OP3 encoder   \n",
       "15737  pilot_towers_nb4_SJ025_mono1_dis1_occ1_boxroom...  OP3 encoder   \n",
       "15738  pilot_towers_nb3_fr015_SJ025_mono1_dis0_occ0_t...  OP3 encoder   \n",
       "15739  pilot_towers_nb5_fr015_SJ030_mono0_dis0_occ0_b...  OP3 encoder   \n",
       "15740  pilot_towers_nb4_fr015_SJ000_gr01_mono1_dis0_o...  OP3 encoder   \n",
       "\n",
       "      Dynamics Type Encoder Pre-training Task Encoder Pre-training Dataset  \\\n",
       "0               MLP   ImageNet classification                     ImageNet   \n",
       "1               MLP   ImageNet classification                     ImageNet   \n",
       "2               MLP   ImageNet classification                     ImageNet   \n",
       "3               MLP   ImageNet classification                     ImageNet   \n",
       "4               MLP   ImageNet classification                     ImageNet   \n",
       "...             ...                       ...                          ...   \n",
       "15736  OP3 dynamics                       NaN                          NaN   \n",
       "15737  OP3 dynamics                       NaN                          NaN   \n",
       "15738  OP3 dynamics                       NaN                          NaN   \n",
       "15739  OP3 dynamics                       NaN                          NaN   \n",
       "15740  OP3 dynamics                       NaN                          NaN   \n",
       "\n",
       "       Encoder Pre-training Seed Encoder Training Task  \\\n",
       "0                            NaN                   NaN   \n",
       "1                            NaN                   NaN   \n",
       "2                            NaN                   NaN   \n",
       "3                            NaN                   NaN   \n",
       "4                            NaN                   NaN   \n",
       "...                          ...                   ...   \n",
       "15736                        NaN  Image Reconstruction   \n",
       "15737                        NaN  Image Reconstruction   \n",
       "15738                        NaN  Image Reconstruction   \n",
       "15739                        NaN  Image Reconstruction   \n",
       "15740                        NaN  Image Reconstruction   \n",
       "\n",
       "      Encoder Training Dataset  Encoder Training Seed Dynamics Training Task  \\\n",
       "0                          NaN                    NaN           L2 on latent   \n",
       "1                          NaN                    NaN           L2 on latent   \n",
       "2                          NaN                    NaN           L2 on latent   \n",
       "3                          NaN                    NaN           L2 on latent   \n",
       "4                          NaN                    NaN           L2 on latent   \n",
       "...                        ...                    ...                    ...   \n",
       "15736                no_towers                    0.0   Image Reconstruction   \n",
       "15737                no_towers                    0.0   Image Reconstruction   \n",
       "15738                no_towers                    0.0   Image Reconstruction   \n",
       "15739                no_towers                    0.0   Image Reconstruction   \n",
       "15740                no_towers                    0.0   Image Reconstruction   \n",
       "\n",
       "      Dynamics Training Dataset  Dynamics Training Seed  \\\n",
       "0                    no_linking                       0   \n",
       "1                    no_linking                       0   \n",
       "2                    no_linking                       0   \n",
       "3                    no_linking                       0   \n",
       "4                    no_linking                       0   \n",
       "...                         ...                     ...   \n",
       "15736                 no_towers                       0   \n",
       "15737                 no_towers                       0   \n",
       "15738                 no_towers                       0   \n",
       "15739                 no_towers                       0   \n",
       "15740                 no_towers                       0   \n",
       "\n",
       "                       filename  correct  \\\n",
       "0      VGGFrozenMLP_results.csv    False   \n",
       "1      VGGFrozenMLP_results.csv    False   \n",
       "2      VGGFrozenMLP_results.csv     True   \n",
       "3      VGGFrozenMLP_results.csv    False   \n",
       "4      VGGFrozenMLP_results.csv     True   \n",
       "...                         ...      ...   \n",
       "15736           OP3_results.csv    False   \n",
       "15737           OP3_results.csv     True   \n",
       "15738           OP3_results.csv    False   \n",
       "15739           OP3_results.csv     True   \n",
       "15740           OP3_results.csv    False   \n",
       "\n",
       "                                     Canon Stimulus Name  \\\n",
       "0      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...   \n",
       "1      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...   \n",
       "2      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...   \n",
       "3      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...   \n",
       "4      pilot_linking_nl1-5_aNone_bCube_occ0_dis0_boxr...   \n",
       "...                                                  ...   \n",
       "15736  pilot_towers_nb2_fr015_SJ010_mono0_dis0_occ0_b...   \n",
       "15737  pilot_towers_nb4_SJ025_mono1_dis1_occ1_boxroom...   \n",
       "15738  pilot_towers_nb3_fr015_SJ025_mono1_dis0_occ0_t...   \n",
       "15739  pilot_towers_nb5_fr015_SJ030_mono0_dis0_occ0_b...   \n",
       "15740  pilot_towers_nb4_fr015_SJ000_gr01_mono1_dis0_o...   \n",
       "\n",
       "      Encoder Training Dataset Type Dynamics Training Dataset Type  \\\n",
       "0                               NaN                   all_but_this   \n",
       "1                               NaN                   all_but_this   \n",
       "2                               NaN                   all_but_this   \n",
       "3                               NaN                   all_but_this   \n",
       "4                               NaN                   all_but_this   \n",
       "...                             ...                            ...   \n",
       "15736                  all_but_this                   all_but_this   \n",
       "15737                  all_but_this                   all_but_this   \n",
       "15738                  all_but_this                   all_but_this   \n",
       "15739                  all_but_this                   all_but_this   \n",
       "15740                  all_but_this                   all_but_this   \n",
       "\n",
       "      Readout Train Data Type  \\\n",
       "0                        same   \n",
       "1                        same   \n",
       "2                        same   \n",
       "3                        same   \n",
       "4                        same   \n",
       "...                       ...   \n",
       "15736                    same   \n",
       "15737                    same   \n",
       "15738                    same   \n",
       "15739                    same   \n",
       "15740                    same   \n",
       "\n",
       "                                                 ModelID  \\\n",
       "0      VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "1      VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "2      VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "3      VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "4      VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "...                                                  ...   \n",
       "15736  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "15737  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "15738  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "15739  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "15740  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "\n",
       "                                              Model Kind  \n",
       "0       VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same  \n",
       "1       VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same  \n",
       "2       VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same  \n",
       "3       VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same  \n",
       "4       VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same  \n",
       "...                                                  ...  \n",
       "15736  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...  \n",
       "15737  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...  \n",
       "15738  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...  \n",
       "15739  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...  \n",
       "15740  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...  \n",
       "\n",
       "[171156 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate labels for regression analysis\n",
    "* Comparison 1: Visual encoder architecture (ConvNet [SVG/VGGFrozenLSTM] vs. transformer [DEITFrozenLSTM] … DEITFrozenMLP vs. SVG/VGGFrozenMLP)\n",
    "* Comparison 2: Dynamics model RNN vs. MLP (LSTM vs. MLP for above)\n",
    "* Comparison 3: Among unsupervised models, object-centric vs. non-object-centric\n",
    "        * {CSWM, OP3} vs. {SVG}\n",
    "* Comparison 4: Latent vs. pixel reconstruction loss\n",
    "        * CSWM vs. OP3\n",
    "* Comparison 5: RPIN vs. CSWM/OP3 (“supervised explicit object-centric” vs. “unsupervised implicit object-centric”)\n",
    "\n",
    "Dimensions: \n",
    "* “Visual encoder architecture” : [“ConvNet” “Transformer” “Neither”]\n",
    "* “Dynamics model architecture” : [“LSTM”, “MLP”, “Neither”]\n",
    "* “ObjectCentric”: [TRUE, FALSE, NA]\n",
    "* “Supervised”: [TRUE, FALSE]\n",
    "* “SelfSupervisedLoss”: [“latent”, “pixel”, “NA”]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:12.703369Z",
     "iopub.status.busy": "2021-06-03T22:26:12.703077Z",
     "iopub.status.idle": "2021-06-03T22:26:13.028588Z",
     "shell.execute_reply": "2021-06-03T22:26:13.027719Z",
     "shell.execute_reply.started": "2021-06-03T22:26:12.703331Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#“Visual encoder architecture” : [“ConvNet” “Transformer” “Neither”]\n",
    "MD['Visual encoder architecture'] = \"Neither\"\n",
    "MD.loc[(MD['Model'].str.contains(\"SVG\")) | (MD['Model'].str.contains(\"VGG\")),'Visual encoder architecture'] = \"ConvNet\"\n",
    "MD.loc[(MD['Model'].str.contains(\"DEIT\")) | (MD['Model'].str.contains(\"VGG\")),'Visual encoder architecture'] = \"Transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:13.031153Z",
     "iopub.status.busy": "2021-06-03T22:26:13.030341Z",
     "iopub.status.idle": "2021-06-03T22:26:13.182584Z",
     "shell.execute_reply": "2021-06-03T22:26:13.181972Z",
     "shell.execute_reply.started": "2021-06-03T22:26:13.030998Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# “Dynamics model architecture” : [“LSTM”, “MLP”, “Neither”]\n",
    "MD['Dynamics model architecture'] = \"Neither\"\n",
    "MD.loc[(MD['Model'].str.contains(\"LSTM\")),'Dynamics model architecture'] = \"LSTM\"\n",
    "MD.loc[(MD['Model'].str.contains(\"MLP\")),'Dynamics model architecture'] = \"MLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:13.183956Z",
     "iopub.status.busy": "2021-06-03T22:26:13.183633Z",
     "iopub.status.idle": "2021-06-03T22:26:13.387724Z",
     "shell.execute_reply": "2021-06-03T22:26:13.386757Z",
     "shell.execute_reply.started": "2021-06-03T22:26:13.183922Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ObjectCentric”: [TRUE, FALSE, NA]\n",
    "MD['ObjectCentric'] = np.nan\n",
    "MD.loc[(MD['Model'].str.contains(\"CSWM\")) | (MD['Model'].str.contains(\"OP3\")),'ObjectCentric'] = True\n",
    "MD.loc[(MD['Model'].str.contains(\"SVG\")),'ObjectCentric'] = False\n",
    "# MD['ObjectCentric'] = MD['ObjectCentric'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:13.389026Z",
     "iopub.status.busy": "2021-06-03T22:26:13.388827Z",
     "iopub.status.idle": "2021-06-03T22:26:13.808147Z",
     "shell.execute_reply": "2021-06-03T22:26:13.806996Z",
     "shell.execute_reply.started": "2021-06-03T22:26:13.389002Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supervised”: [TRUE, FALSE]\n",
    "MD['Supervised'] = np.nan\n",
    "MD.loc[(MD['Model'].str.contains(\"RPIN\")) | (MD['Model'].str.contains(\"DPI\")),'Supervised'] = True\n",
    "MD.loc[(MD['Model'].str.contains(\"CSWM\")) | (MD['Model'].str.contains(\"OP3\")) | (MD['Model'].str.contains(\"SVG\") | (MD['Model'].str.contains(\"VGG\"))),'Supervised'] = False\n",
    "# MD['Supervised'] = MD['Supervised'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:13.810199Z",
     "iopub.status.busy": "2021-06-03T22:26:13.809724Z",
     "iopub.status.idle": "2021-06-03T22:26:14.141538Z",
     "shell.execute_reply": "2021-06-03T22:26:14.140849Z",
     "shell.execute_reply.started": "2021-06-03T22:26:13.810159Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SelfSupervisedLoss”: [“latent”, “pixel”, “NA”]\n",
    "MD['SelfSupervisedLossSelfSupervisedLoss'] = \"NA\"\n",
    "MD.loc[(MD['Model'].str.contains(\"CSWM\")),'SelfSupervisedLoss'] = \"latent\"\n",
    "MD.loc[(MD['Model'].str.contains(\"OP3\")) | (MD['Model'].str.contains(\"VGG\")) | (MD['Model'].str.contains(\"SVG\") | (MD['Model'].str.contains(\"VGG\"))),'SelfSupervisedLoss'] = \"pixel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:14.142783Z",
     "iopub.status.busy": "2021-06-03T22:26:14.142532Z",
     "iopub.status.idle": "2021-06-03T22:26:14.146548Z",
     "shell.execute_reply": "2021-06-03T22:26:14.145682Z",
     "shell.execute_reply.started": "2021-06-03T22:26:14.142757Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save as model identifying column\n",
    "MODEL_COLS = h.MODEL_COLS + ['Visual encoder architecture','Dynamics model architecture','ObjectCentric','Supervised','SelfSupervisedLossSelfSupervisedLoss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate summary table of human 95% CIs for accuracy across all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:14.148385Z",
     "iopub.status.busy": "2021-06-03T22:26:14.148173Z",
     "iopub.status.idle": "2021-06-03T22:26:25.273123Z",
     "shell.execute_reply": "2021-06-03T22:26:25.272112Z",
     "shell.execute_reply.started": "2021-06-03T22:26:14.148360Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file! Done.\n"
     ]
    }
   ],
   "source": [
    "## init human_bootstrapped_accuracy for plotting\n",
    "human_bootstrapped_accuracy = pd.DataFrame()\n",
    "\n",
    "for exp_ind, exp_name in enumerate(resp_paths):\n",
    "    \n",
    "    ## get path to response data\n",
    "    path_to_data = resp_paths[exp_ind]\n",
    "\n",
    "    ## load data and apply preprocessing\n",
    "    _D = h.load_and_preprocess_data(path_to_data)\n",
    "    scenarioName = _D.scenarioName.values[0]\n",
    "    print('Currently analyzing the {} experiment.'.format(_D.scenarioName.values[0]))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    ## apply exclusion criteria\n",
    "    D = h.apply_exclusion_criteria(_D)\n",
    "\n",
    "    ## compute bootstrapped sampling distributions of accuracy\n",
    "    Dacc = D.groupby('prolificIDAnon').agg({'correct':np.mean})\n",
    "    bootmeans = h.bootstrap_mean(Dacc, col='correct', nIter=1000)\n",
    "\n",
    "    obsmean = np.mean(Dacc.correct.values)\n",
    "    bootmean = np.mean(bootmeans)\n",
    "    lb = np.percentile(bootmeans,2.5)\n",
    "    ub = np.percentile(bootmeans,97.5)\n",
    "    pct25 = np.percentile(Dacc,2.5)\n",
    "    pct975 = np.percentile(Dacc,97.5)\n",
    "    ## merge bootstrapped accuracy estimates\n",
    "    if len(human_bootstrapped_accuracy)==0:\n",
    "        human_bootstrapped_accuracy = pd.DataFrame(['human', scenarioName, obsmean,bootmean,lb,ub, pct25, pct975]).transpose()\n",
    "    else:\n",
    "        human_bootstrapped_accuracy = pd.concat([human_bootstrapped_accuracy, pd.DataFrame(['human', scenarioName, obsmean,bootmean,lb,ub, pct25, pct975]).transpose()],axis=0)\n",
    "        \n",
    "## add column names        \n",
    "human_bootstrapped_accuracy.columns=['agent','scenario','obs_mean', 'boot_mean', 'ci_lb', 'ci_ub', 'pct_2.5', 'pct_97.5']\n",
    "\n",
    "## save out human_bootstrapped_accuracy to re-plot in R\n",
    "if not os.path.exists(os.path.join(csv_dir, 'summary')):\n",
    "    os.makedirs(os.path.join(csv_dir, 'summary'))    \n",
    "human_bootstrapped_accuracy.to_csv(os.path.join(csv_dir, 'summary','human_accuracy_by_scenario.csv'), index=False)\n",
    "print('Saved to file! Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:25.282646Z",
     "iopub.status.busy": "2021-06-03T22:26:25.282417Z",
     "iopub.status.idle": "2021-06-03T22:26:25.295412Z",
     "shell.execute_reply": "2021-06-03T22:26:25.294819Z",
     "shell.execute_reply.started": "2021-06-03T22:26:25.282624Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>scenario</th>\n",
       "      <th>obs_mean</th>\n",
       "      <th>boot_mean</th>\n",
       "      <th>ci_lb</th>\n",
       "      <th>ci_ub</th>\n",
       "      <th>pct_2.5</th>\n",
       "      <th>pct_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>collision</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.808485</td>\n",
       "      <td>0.798793</td>\n",
       "      <td>0.81766</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>rollingsliding</td>\n",
       "      <td>0.882986</td>\n",
       "      <td>0.882948</td>\n",
       "      <td>0.875411</td>\n",
       "      <td>0.890696</td>\n",
       "      <td>0.789167</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>dominoes</td>\n",
       "      <td>0.692791</td>\n",
       "      <td>0.6927</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.701163</td>\n",
       "      <td>0.614167</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>drop</td>\n",
       "      <td>0.743368</td>\n",
       "      <td>0.743417</td>\n",
       "      <td>0.735504</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.804333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.678222</td>\n",
       "      <td>0.663729</td>\n",
       "      <td>0.692269</td>\n",
       "      <td>0.543667</td>\n",
       "      <td>0.771667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>linking</td>\n",
       "      <td>0.643182</td>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.631968</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.536833</td>\n",
       "      <td>0.744333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>containment</td>\n",
       "      <td>0.766988</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.758072</td>\n",
       "      <td>0.775026</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.839667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>towers</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.763012</td>\n",
       "      <td>0.754975</td>\n",
       "      <td>0.770982</td>\n",
       "      <td>0.669333</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent        scenario  obs_mean boot_mean     ci_lb     ci_ub   pct_2.5  \\\n",
       "0  human       collision  0.808511  0.808485  0.798793   0.81766  0.704333   \n",
       "0  human  rollingsliding  0.882986  0.882948  0.875411  0.890696  0.789167   \n",
       "0  human        dominoes  0.692791    0.6927  0.684341  0.701163  0.614167   \n",
       "0  human            drop  0.743368  0.743417  0.735504    0.7513  0.666667   \n",
       "0  human      clothiness  0.678133  0.678222  0.663729  0.692269  0.543667   \n",
       "0  human         linking  0.643182  0.643234  0.631968  0.654545  0.536833   \n",
       "0  human     containment  0.766988  0.766892  0.758072  0.775026  0.686667   \n",
       "0  human          towers  0.763137  0.763012  0.754975  0.770982  0.669333   \n",
       "\n",
       "   pct_97.5  \n",
       "0      0.88  \n",
       "0      0.94  \n",
       "0      0.76  \n",
       "0  0.804333  \n",
       "0  0.771667  \n",
       "0  0.744333  \n",
       "0  0.839667  \n",
       "0     0.826  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_bootstrapped_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-human consistency across stimuli (within scenario)\n",
    "We will analyze human-human consistency by computing the mean correlation between (binary) response vectors produced by each human participant across all stimuli within each scenario. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:25.299368Z",
     "iopub.status.busy": "2021-06-03T22:26:25.298931Z",
     "iopub.status.idle": "2021-06-03T22:26:32.969724Z",
     "shell.execute_reply": "2021-06-03T22:26:32.969038Z",
     "shell.execute_reply.started": "2021-06-03T22:26:25.299330Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file! Done.\n"
     ]
    }
   ],
   "source": [
    "## init human_boot_corr for plotting\n",
    "human_boot_corr = pd.DataFrame()\n",
    "\n",
    "for exp_ind, exp_name in enumerate(resp_paths):\n",
    "    \n",
    "    ## get path to response data\n",
    "    path_to_data = resp_paths[exp_ind]\n",
    "\n",
    "    ## load data and apply preprocessing\n",
    "    _D = h.load_and_preprocess_data(path_to_data)\n",
    "    scenarioName = _D.scenarioName.values[0]\n",
    "    print('Currently analyzing the {} experiment.'.format(_D.scenarioName.values[0]))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    ## apply exclusion criteria\n",
    "    D = h.apply_exclusion_criteria(_D)\n",
    "    \n",
    "    ## create response feature matrix (numSubs x numTrialsPerSub)\n",
    "    D2 = D.sort_values(by=['prolificIDAnon','stim_ID']).reset_index(drop=True)\n",
    "    numSubs = len(np.unique(D['prolificIDAnon'].values))\n",
    "    numTrialsPerSub = int(len(D)/numSubs)\n",
    "    respMat = np.reshape(D2['responseBool'].values, (numSubs,numTrialsPerSub)) \n",
    "\n",
    "    ## sanity check that the reshape operation happened correctly\n",
    "    assert len([i for (i,j) in list(zip(respMat[0],D2[:150]['responseBool'].values)) if i!=j])==0    \n",
    "    \n",
    "    ## get pairwise correlations\n",
    "    dists = 1-scipy.spatial.distance.pdist(respMat, metric='correlation')\n",
    "    corrMat = scipy.spatial.distance.squareform(dists)\n",
    "    \n",
    "    ## get percentiles over pairwise corrs\n",
    "    pairwiseCorrs = corrMat[np.triu_indices(n=len(corrMat), k=1)]\n",
    "    lb = np.percentile(pairwiseCorrs, 2.5)\n",
    "    med = np.percentile(pairwiseCorrs, 50)\n",
    "    ub = np.percentile(pairwiseCorrs, 97.5)  \n",
    "        \n",
    "    if len(human_boot_corr)==0:\n",
    "        human_boot_corr = pd.DataFrame(['human', scenarioName, lb, med, ub]).transpose()\n",
    "    else:\n",
    "        human_boot_corr = pd.concat([human_boot_corr, pd.DataFrame(['human', scenarioName, lb, med, ub]).transpose()],axis=0)\n",
    "        \n",
    "## add column names        \n",
    "human_boot_corr.columns=['agent','scenario','corr_lb', 'corr_med', 'corr_ub']\n",
    "\n",
    "## save out human_boot_corr to re-plot in R\n",
    "if not os.path.exists(os.path.join(csv_dir, 'summary')):\n",
    "    os.makedirs(os.path.join(csv_dir, 'summary'))    \n",
    "human_boot_corr.to_csv(os.path.join(csv_dir, 'summary','human_pairwiseCorrs_by_scenario.csv'), index=False)\n",
    "print('Saved to file! Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:32.971856Z",
     "iopub.status.busy": "2021-06-03T22:26:32.971361Z",
     "iopub.status.idle": "2021-06-03T22:26:32.985143Z",
     "shell.execute_reply": "2021-06-03T22:26:32.983785Z",
     "shell.execute_reply.started": "2021-06-03T22:26:32.971810Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>scenario</th>\n",
       "      <th>corr_lb</th>\n",
       "      <th>corr_med</th>\n",
       "      <th>corr_ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>collision</td>\n",
       "      <td>0.388046</td>\n",
       "      <td>0.62822</td>\n",
       "      <td>0.776057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>rollingsliding</td>\n",
       "      <td>0.506253</td>\n",
       "      <td>0.713836</td>\n",
       "      <td>0.851243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>dominoes</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>0.425943</td>\n",
       "      <td>0.591814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>drop</td>\n",
       "      <td>0.266334</td>\n",
       "      <td>0.501544</td>\n",
       "      <td>0.681139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.0654259</td>\n",
       "      <td>0.349287</td>\n",
       "      <td>0.549326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>linking</td>\n",
       "      <td>0.114636</td>\n",
       "      <td>0.386807</td>\n",
       "      <td>0.569892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>containment</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.559038</td>\n",
       "      <td>0.725013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>towers</td>\n",
       "      <td>0.299731</td>\n",
       "      <td>0.565581</td>\n",
       "      <td>0.725722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent        scenario    corr_lb  corr_med   corr_ub\n",
       "0  human       collision   0.388046   0.62822  0.776057\n",
       "0  human  rollingsliding   0.506253  0.713836  0.851243\n",
       "0  human        dominoes   0.231102  0.425943  0.591814\n",
       "0  human            drop   0.266334  0.501544  0.681139\n",
       "0  human      clothiness  0.0654259  0.349287  0.549326\n",
       "0  human         linking   0.114636  0.386807  0.569892\n",
       "0  human     containment   0.306122  0.559038  0.725013\n",
       "0  human          towers   0.299731  0.565581  0.725722"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_boot_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:32.987150Z",
     "iopub.status.busy": "2021-06-03T22:26:32.986781Z",
     "iopub.status.idle": "2021-06-03T22:26:55.625918Z",
     "shell.execute_reply": "2021-06-03T22:26:55.625098Z",
     "shell.execute_reply.started": "2021-06-03T22:26:32.987079Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file! Done.\n"
     ]
    }
   ],
   "source": [
    "## init human_boot_cohenk for plotting\n",
    "human_boot_cohenk = pd.DataFrame()\n",
    "\n",
    "for exp_ind, exp_name in enumerate(resp_paths):\n",
    "    \n",
    "    ## get path to response data\n",
    "    path_to_data = resp_paths[exp_ind]\n",
    "\n",
    "    ## load data and apply preprocessing\n",
    "    _D = h.load_and_preprocess_data(path_to_data)\n",
    "    scenarioName = _D.scenarioName.values[0]\n",
    "    print('Currently analyzing the {} experiment.'.format(_D.scenarioName.values[0]))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    ## apply exclusion criteria\n",
    "    D = h.apply_exclusion_criteria(_D)\n",
    "    \n",
    "    ## create response feature matrix (numSubs x numTrialsPerSub)\n",
    "    D2 = D.sort_values(by=['prolificIDAnon','stim_ID']).reset_index(drop=True)\n",
    "    numSubs = len(np.unique(D['prolificIDAnon'].values))\n",
    "    numTrialsPerSub = int(len(D)/numSubs)\n",
    "    respMat = np.reshape(D2['responseBool'].values, (numSubs,numTrialsPerSub)) \n",
    "\n",
    "    ## sanity check that the reshape operation happened correctly\n",
    "    assert len([i for (i,j) in list(zip(respMat[0],D2[:150]['responseBool'].values)) if i!=j])==0    \n",
    "      \n",
    "    ## compute Cohen's kappa\n",
    "    ## with a horrific double loop\n",
    "    kappas = []\n",
    "    for i in range(respMat.shape[0]): # for each participant\n",
    "        for j in range(i+1,respMat.shape[0]): # compare to every participant after them\n",
    "            assert i != j\n",
    "            kappa = sklearn.metrics.cohen_kappa_score(respMat[i],respMat[j])\n",
    "            kappas.append(kappa)\n",
    "    \n",
    "    ## get percentiles over pairwise corrs\n",
    "    lb = np.percentile(kappas, 2.5)\n",
    "    med = np.percentile(kappas, 50)\n",
    "    ub = np.percentile(kappas, 97.5)  \n",
    "        \n",
    "    if len(human_boot_cohenk)==0:\n",
    "        human_boot_cohenk = pd.DataFrame(['human', scenarioName, lb, med, ub]).transpose()\n",
    "    else:\n",
    "        human_boot_cohenk = pd.concat([human_boot_cohenk, pd.DataFrame(['human', scenarioName, lb, med, ub]).transpose()],axis=0)\n",
    "        \n",
    "## add column names        \n",
    "human_boot_cohenk.columns=['agent','scenario','corr_lb', 'corr_med', 'corr_ub']\n",
    "\n",
    "## save out human_boot_cohenk to re-plot in R\n",
    "if not os.path.exists(os.path.join(csv_dir, 'summary')):\n",
    "    os.makedirs(os.path.join(csv_dir, 'summary'))    \n",
    "human_boot_cohenk.to_csv(os.path.join(csv_dir, 'summary','human_pairwiseCohensKs_by_scenario.csv'), index=False)\n",
    "print('Saved to file! Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:55.627906Z",
     "iopub.status.busy": "2021-06-03T22:26:55.627663Z",
     "iopub.status.idle": "2021-06-03T22:26:55.642502Z",
     "shell.execute_reply": "2021-06-03T22:26:55.641626Z",
     "shell.execute_reply.started": "2021-06-03T22:26:55.627880Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>scenario</th>\n",
       "      <th>corr_lb</th>\n",
       "      <th>corr_med</th>\n",
       "      <th>corr_ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>collision</td>\n",
       "      <td>0.381969</td>\n",
       "      <td>0.621826</td>\n",
       "      <td>0.773353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>rollingsliding</td>\n",
       "      <td>0.490152</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.85095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>dominoes</td>\n",
       "      <td>0.221083</td>\n",
       "      <td>0.417313</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>drop</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>0.494367</td>\n",
       "      <td>0.678875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.0624156</td>\n",
       "      <td>0.340571</td>\n",
       "      <td>0.542955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>linking</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.369462</td>\n",
       "      <td>0.560538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>containment</td>\n",
       "      <td>0.284806</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.719987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>towers</td>\n",
       "      <td>0.285117</td>\n",
       "      <td>0.549918</td>\n",
       "      <td>0.720673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent        scenario    corr_lb  corr_med   corr_ub\n",
       "0  human       collision   0.381969  0.621826  0.773353\n",
       "0  human  rollingsliding   0.490152  0.707031   0.85095\n",
       "0  human        dominoes   0.221083  0.417313  0.586667\n",
       "0  human            drop   0.260437  0.494367  0.678875\n",
       "0  human      clothiness  0.0624156  0.340571  0.542955\n",
       "0  human         linking   0.109512  0.369462  0.560538\n",
       "0  human     containment   0.284806  0.546667  0.719987\n",
       "0  human          towers   0.285117  0.549918  0.720673"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_boot_cohenk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution of model physical judgments, by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute summary statistics over model physical judgments, by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:55.644595Z",
     "iopub.status.busy": "2021-06-03T22:26:55.644129Z",
     "iopub.status.idle": "2021-06-03T22:26:56.004160Z",
     "shell.execute_reply": "2021-06-03T22:26:56.003351Z",
     "shell.execute_reply.started": "2021-06-03T22:26:55.644555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dacc = D.groupby('stim_ID').agg({'correct':np.mean})\n",
    "p = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct human-model comparisons\n",
    "We will compare human and model behavior in two ways: **absolute performance** and **response pattern.**\n",
    "\n",
    "#### **Absolute Performance** \n",
    "We will compare the accuracy of each model to the mean accuracy of humans, for each scenario. \n",
    "To do this, we will first compute estimates of mean human accuracy for each scenario and construct 95% confidence intervals for each of these estimates. \n",
    "These confidence intervals will be constructed by bootstrapping: specifically, for an experiment with N participants, we will resample N participants with replacement and compute the proportion correct for that bootstrapped sample. We will take repeat this resampling procedure 1000 times to generate a sampling distribution for the mean proportion correct. The 2.5th and 97.5th percentile will be extracted from this sampling distribution to provide the lower and upper bounds of the 95% confidence interval.\n",
    "\n",
    "For each model, we will then compare their proportion correct (a point estimate) to the human confidence interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:56.005598Z",
     "iopub.status.busy": "2021-06-03T22:26:56.005314Z",
     "iopub.status.idle": "2021-06-03T22:26:56.199393Z",
     "shell.execute_reply": "2021-06-03T22:26:56.198699Z",
     "shell.execute_reply.started": "2021-06-03T22:26:56.005571Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group model data by scenario\n",
    "MD_by_scenario = MD.groupby(['Readout Test Data','ModelID']).agg(\n",
    "        {**{ 'correct':'mean' },\n",
    "         **{ col:'first' for col in MODEL_COLS+h.DATASET_ABSTRACTED_COLS} #save model identifying data as well\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:56.200807Z",
     "iopub.status.busy": "2021-06-03T22:26:56.200631Z",
     "iopub.status.idle": "2021-06-03T22:26:57.954792Z",
     "shell.execute_reply": "2021-06-03T22:26:57.953906Z",
     "shell.execute_reply.started": "2021-06-03T22:26:56.200787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file. Done!\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "\n",
    "for scenario in sorted(MD['Readout Test Data'].unique()):\n",
    "    print(\"Now running scenario\",scenario)\n",
    "    _MD_by_scenario = MD_by_scenario.loc[[scenario]]\n",
    "    for _,model_row in list(_MD_by_scenario.iterrows()):\n",
    "        #each model is one row of MD\n",
    "        human_row = human_bootstrapped_accuracy.query(\"scenario == @scenario\")\n",
    "#         assert len(model_row) == len(human_row) == 1\n",
    "        correct_ratio = model_row['correct']/human_row['obs_mean']\n",
    "        correct_diff = model_row['correct'] - human_row['obs_mean']\n",
    "        accuracies[(scenario,model_row.name[1])] = {**{\n",
    "                                                    'scenario': scenario,\n",
    "                                                    'ratio': float(correct_ratio), \n",
    "                                                    'diff': float(correct_diff),\n",
    "                                                    'human_correct': float(human_row['obs_mean']),\n",
    "                                                    'model_correct': float(model_row['correct']),\n",
    "                                                    },**{col: model_row[col] for col in MODEL_COLS+h.DATASET_ABSTRACTED_COLS}} # save information for model identification\n",
    "    clear_output(wait=True)\n",
    "\n",
    "model_human_accuracies = pd.DataFrame(accuracies).transpose()  \n",
    "model_human_accuracies.to_csv(os.path.join(csv_dir, 'summary','model_human_accuracies.csv'), index=False)\n",
    "print('Saved to file. Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:57.956809Z",
     "iopub.status.busy": "2021-06-03T22:26:57.956203Z",
     "iopub.status.idle": "2021-06-03T22:26:57.991023Z",
     "shell.execute_reply": "2021-06-03T22:26:57.990131Z",
     "shell.execute_reply.started": "2021-06-03T22:26:57.956776Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>ratio</th>\n",
       "      <th>diff</th>\n",
       "      <th>human_correct</th>\n",
       "      <th>model_correct</th>\n",
       "      <th>Model</th>\n",
       "      <th>Readout Train Data</th>\n",
       "      <th>Readout Type</th>\n",
       "      <th>Encoder Type</th>\n",
       "      <th>Dynamics Type</th>\n",
       "      <th>Encoder Pre-training Task</th>\n",
       "      <th>Encoder Pre-training Dataset</th>\n",
       "      <th>Encoder Pre-training Seed</th>\n",
       "      <th>Encoder Training Task</th>\n",
       "      <th>Encoder Training Dataset</th>\n",
       "      <th>Encoder Training Seed</th>\n",
       "      <th>Dynamics Training Task</th>\n",
       "      <th>Dynamics Training Dataset</th>\n",
       "      <th>Dynamics Training Seed</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>Model Kind</th>\n",
       "      <th>Visual encoder architecture</th>\n",
       "      <th>Dynamics model architecture</th>\n",
       "      <th>ObjectCentric</th>\n",
       "      <th>Supervised</th>\n",
       "      <th>SelfSupervisedLossSelfSupervisedLoss</th>\n",
       "      <th>Encoder Training Dataset Type</th>\n",
       "      <th>Dynamics Training Dataset Type</th>\n",
       "      <th>Readout Train Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">clothiness</th>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_all_readout_A_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>1.0152</td>\n",
       "      <td>0.0103089</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_all_readout_B_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.792895</td>\n",
       "      <td>-0.140445</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.537688</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_all_readout_C_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>-0.170596</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>C</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_clothiness_Contrastive_0_clothiness_readout_A_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.874407</td>\n",
       "      <td>-0.0851685</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_same_Contras...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_clothiness_Contrastive_0_clothiness_readout_B_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.785485</td>\n",
       "      <td>-0.14547</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.532663</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_same_Contras...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">towers</th>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_towers_readout_B_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.838863</td>\n",
       "      <td>-0.12297</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.640167</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_towers_readout_C_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>-0.102049</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.661088</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_towers_readout_A_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.970449</td>\n",
       "      <td>-0.0225515</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>A</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_towers_readout_B_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.816932</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.623431</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_towers_readout_C_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>-0.135522</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.627615</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 scenario  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  clothiness   \n",
       "...                                                                   ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      towers   \n",
       "\n",
       "                                                                  ratio  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...    1.0152   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  0.792895   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  0.748433   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  0.874407   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  0.785485   \n",
       "...                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.838863   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.866276   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  0.970449   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  0.816932   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  0.822414   \n",
       "\n",
       "                                                                    diff  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  0.0103089   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  -0.140445   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  -0.170596   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co... -0.0851685   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...   -0.14547   \n",
       "...                                                                  ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   -0.12297   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  -0.102049   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow... -0.0225515   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  -0.139706   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  -0.135522   \n",
       "\n",
       "                                                              human_correct  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.678133   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.763137   \n",
       "\n",
       "                                                              model_correct  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.688442   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.537688   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.507538   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.592965   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.532663   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.640167   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.661088   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.740586   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.623431   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.627615   \n",
       "\n",
       "                                                                      Model  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          CSWM   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP   \n",
       "\n",
       "                                                              Readout Train Data  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...         clothiness   \n",
       "...                                                                          ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...             towers   \n",
       "\n",
       "                                                              Readout Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            A   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            B   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            C   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            A   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            B   \n",
       "...                                                                    ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            B   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            C   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            A   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            B   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            C   \n",
       "\n",
       "                                                               Encoder Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM encoder   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           VGG   \n",
       "\n",
       "                                                               Dynamics Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM dynamics   \n",
       "...                                                                      ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            MLP   \n",
       "\n",
       "                                                              Encoder Pre-training Task  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "...                                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   ImageNet classification   \n",
       "\n",
       "                                                              Encoder Pre-training Dataset  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          NaN   \n",
       "...                                                                                    ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                     ImageNet   \n",
       "\n",
       "                                                              Encoder Pre-training Seed  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "...                                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                       NaN   \n",
       "\n",
       "                                                              Encoder Training Task  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...           Contrastive   \n",
       "...                                                                             ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "\n",
       "                                                              Encoder Training Dataset  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...               clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...               clothiness   \n",
       "...                                                                                ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      NaN   \n",
       "\n",
       "                                                              Encoder Training Seed  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     0   \n",
       "...                                                                             ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "\n",
       "                                                              Dynamics Training Task  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            Contrastive   \n",
       "...                                                                              ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           L2 on latent   \n",
       "\n",
       "                                                              Dynamics Training Dataset  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                clothiness   \n",
       "...                                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 no_towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 no_towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    towers   \n",
       "\n",
       "                                                              Dynamics Training Seed  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                      0   \n",
       "...                                                                              ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      0   \n",
       "\n",
       "                                                                                                         ModelID  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...   \n",
       "...                                                                                                          ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...   \n",
       "\n",
       "                                                                                                      Model Kind  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_same_Contras...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_same_Contras...   \n",
       "...                                                                                                          ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "\n",
       "                                                              Visual encoder architecture  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "...                                                                                   ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                 Transformer   \n",
       "\n",
       "                                                              Dynamics model architecture  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "...                                                                                   ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                         MLP   \n",
       "\n",
       "                                                              ObjectCentric  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          True   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           NaN   \n",
       "\n",
       "                                                              Supervised  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      False   \n",
       "...                                                                  ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      False   \n",
       "\n",
       "                                                              SelfSupervisedLossSelfSupervisedLoss  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                                   NA   \n",
       "...                                                                                            ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                                   NA   \n",
       "\n",
       "                                                              Encoder Training Dataset Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                           all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                           all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                           all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          same   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          same   \n",
       "...                                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           NaN   \n",
       "\n",
       "                                                              Dynamics Training Dataset Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                            all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                            all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                            all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                           same   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                           same   \n",
       "...                                                                                      ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           same   \n",
       "\n",
       "                                                              Readout Train Data Type  \n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                    same  \n",
       "...                                                                               ...  \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    same  \n",
       "\n",
       "[816 rows x 29 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_human_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Response Pattern**\n",
    "We will compare the pattern of predictions generated by each model to the pattern of predictions generated by humans. \n",
    "\n",
    "We will do this by using two standard inter-rater reliability metrics:\n",
    "##### **Correlation**\n",
    "For each pair of human participants, we will compute the correlation between their (binary) response vectors, yielding a distribution of pairwise human-human correlations. \n",
    "For each model, we will compute the correlation between its response vector and every human participant, as well as every other model. \n",
    "A model's response pattern will be considered more similar to humans' insofar as the mean model-human correlation (across humans) lies closer to the mean human-human correlation (for all pairs of humans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:26:57.992891Z",
     "iopub.status.busy": "2021-06-03T22:26:57.992459Z",
     "iopub.status.idle": "2021-06-03T22:30:50.973190Z",
     "shell.execute_reply": "2021-06-03T22:30:50.972241Z",
     "shell.execute_reply.started": "2021-06-03T22:26:57.992865Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file. Done!\n"
     ]
    }
   ],
   "source": [
    "out_dict = {}\n",
    "\n",
    "for scenario in sorted(MD['Readout Test Data'].unique()):\n",
    "    print(\"Now running scenario\",scenario)\n",
    "    _MD = MD[MD['Readout Test Data'] == scenario]\n",
    "    _HD = HD[HD['scenarioName'] == scenario]\n",
    "    for model in _MD['ModelID'].unique():\n",
    "        measures_for_model = []\n",
    "        #get responses of model        \n",
    "        _MD_model = _MD[_MD['ModelID'] == model]\n",
    "        _MD_model = _MD_model.sort_values('Canon Stimulus Name') #ensure same stim order\n",
    "        if len(_MD_model) == 0: continue # no model found\n",
    "        #iterate over the 100 or so participants\n",
    "        for gameID in _HD['gameID'].unique():\n",
    "            #get one game\n",
    "            _HD_game = _HD[_HD['gameID']==gameID]\n",
    "            #ensure stim order\n",
    "            _HD_game = _HD_game.sort_values('stim_ID')\n",
    "            #in case the models have more or less responses compared to humans\n",
    "            human_stim_names = list(_HD_game['stim_ID'])\n",
    "            model_stim_names = list(_MD_model['Canon Stimulus Name'])\n",
    "            joint_stim_names = set(human_stim_names).intersection(set(model_stim_names))\n",
    "            if len(joint_stim_names) == 0:\n",
    "                print(\"⛔️ {} is missing all datapoints on {} human responses\".format(model, len(human_stim_names)),end=\"\\r\")\n",
    "                continue #ignore and move on\n",
    "            if len(human_stim_names) > len(joint_stim_names):\n",
    "                print(\"⚠️ {} is missing {} datapoints on {} human responses\".format(model,len(human_stim_names) - len(joint_stim_names), len(human_stim_names)),end=\"\\r\")\n",
    "            #subset both models to ensure only common stims are used\n",
    "            _MD_model = _MD_model[_MD_model['Canon Stimulus Name'].isin(joint_stim_names)]            \n",
    "            _HD_game = _HD_game[_HD_game['stim_ID'].isin(joint_stim_names)]\n",
    "            #pull response vector\n",
    "            human_responses = np.array(_HD_game['responseBool'].astype(int)) #get human response and cast to int\n",
    "            model_responses = np.array(_MD_model['Predicted Outcome'])\n",
    "#             assert list(model_stim_names) == list(human_stim_names), \"experimental and test stims don't match\"\n",
    "            assert len(model_responses) == len(human_responses), \"More than 1 observation per stimulus\"\n",
    "            # compute correlation\n",
    "            measure = scipy.spatial.distance.correlation(model_responses,human_responses, centered=False)\n",
    "            measures_for_model.append(measure)\n",
    "        if len(measures_for_model) == 0:\n",
    "            print(\"⛔️ {} is missing all datapoints on human responses\".format(model))\n",
    "            continue\n",
    "        # get percentiles over the range of measures\n",
    "        lb = np.percentile(measures_for_model, 2.5)\n",
    "        med = np.percentile(measures_for_model, 50)\n",
    "        ub = np.percentile(measures_for_model, 97.5)\n",
    "        out_dict[(scenario, model)] = {**{'scenario':scenario,\n",
    "                                       'corr_lb':lb,\n",
    "                                       'corr_med':med,\n",
    "                                       'corr_ub':ub,\n",
    "                                       'num_datapoints':len(measures_for_model)},\n",
    "                                       **{col:_MD_model.head(1)[col].item() for col in MODEL_COLS+h.DATASET_ABSTRACTED_COLS} #save model ID info\n",
    "                                      }\n",
    "        clear_output(wait=True)\n",
    "\n",
    "model_human_correlations = pd.DataFrame(out_dict).transpose()  \n",
    "model_human_correlations.to_csv(os.path.join(csv_dir, 'summary','model_human_correlations.csv'), index=False)\n",
    "print('Saved to file. Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:30:50.975232Z",
     "iopub.status.busy": "2021-06-03T22:30:50.974765Z",
     "iopub.status.idle": "2021-06-03T22:30:51.030306Z",
     "shell.execute_reply": "2021-06-03T22:30:51.025433Z",
     "shell.execute_reply.started": "2021-06-03T22:30:50.975185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>corr_lb</th>\n",
       "      <th>corr_med</th>\n",
       "      <th>corr_ub</th>\n",
       "      <th>num_datapoints</th>\n",
       "      <th>Model</th>\n",
       "      <th>Readout Train Data</th>\n",
       "      <th>Readout Type</th>\n",
       "      <th>Encoder Type</th>\n",
       "      <th>Dynamics Type</th>\n",
       "      <th>Encoder Pre-training Task</th>\n",
       "      <th>Encoder Pre-training Dataset</th>\n",
       "      <th>Encoder Pre-training Seed</th>\n",
       "      <th>Encoder Training Task</th>\n",
       "      <th>Encoder Training Dataset</th>\n",
       "      <th>Encoder Training Seed</th>\n",
       "      <th>Dynamics Training Task</th>\n",
       "      <th>Dynamics Training Dataset</th>\n",
       "      <th>Dynamics Training Seed</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>Model Kind</th>\n",
       "      <th>Visual encoder architecture</th>\n",
       "      <th>Dynamics model architecture</th>\n",
       "      <th>ObjectCentric</th>\n",
       "      <th>Supervised</th>\n",
       "      <th>SelfSupervisedLossSelfSupervisedLoss</th>\n",
       "      <th>Encoder Training Dataset Type</th>\n",
       "      <th>Dynamics Training Dataset Type</th>\n",
       "      <th>Readout Train Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">clothiness</th>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all_readout_A_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.283042</td>\n",
       "      <td>0.367758</td>\n",
       "      <td>0.473154</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all_readout_B_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.333465</td>\n",
       "      <td>0.428957</td>\n",
       "      <td>0.518126</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all_readout_C_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.344311</td>\n",
       "      <td>0.435573</td>\n",
       "      <td>0.518126</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>C</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_clothiness_readout_A_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.271644</td>\n",
       "      <td>0.37926</td>\n",
       "      <td>0.46885</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_clothiness_readout_B_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.337023</td>\n",
       "      <td>0.441738</td>\n",
       "      <td>0.541262</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">towers</th>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_towers_Image Reconstruction_0_towers_readout_B_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.317019</td>\n",
       "      <td>0.390006</td>\n",
       "      <td>0.484982</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_tower...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_same_...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_towers_Image Reconstruction_0_towers_readout_C_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.28963</td>\n",
       "      <td>0.371154</td>\n",
       "      <td>0.461487</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_tower...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_same_...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_no_towers_Image Reconstruction_0_no_towers_readout_A_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.283763</td>\n",
       "      <td>0.364515</td>\n",
       "      <td>0.450818</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>A</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_no_towers_Image Reconstruction_0_no_towers_readout_B_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.385081</td>\n",
       "      <td>0.472249</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_no_towers_Image Reconstruction_0_no_towers_readout_C_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.313526</td>\n",
       "      <td>0.388986</td>\n",
       "      <td>0.471993</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 scenario  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  clothiness   \n",
       "...                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      towers   \n",
       "\n",
       "                                                                corr_lb  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.283042   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.333465   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.344311   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.271644   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.337023   \n",
       "...                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  0.317019   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...   0.28963   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.283763   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.302377   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.313526   \n",
       "\n",
       "                                                               corr_med  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.367758   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.428957   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.435573   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   0.37926   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.441738   \n",
       "...                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  0.390006   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  0.371154   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.364515   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.385081   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.388986   \n",
       "\n",
       "                                                                corr_ub  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.473154   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.518126   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  0.518126   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   0.46885   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.541262   \n",
       "...                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  0.484982   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  0.461487   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.450818   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.472249   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  0.471993   \n",
       "\n",
       "                                                              num_datapoints  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             75   \n",
       "...                                                                      ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             89   \n",
       "\n",
       "                                                                      Model  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "...                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...           OP3   \n",
       "\n",
       "                                                              Readout Train Data  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...         clothiness   \n",
       "...                                                                          ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             towers   \n",
       "\n",
       "                                                              Readout Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...            A   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...            B   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...            C   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            A   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            B   \n",
       "...                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...            B   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...            C   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...            A   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...            B   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...            C   \n",
       "\n",
       "                                                              Encoder Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...          VGG   \n",
       "...                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 encoder   \n",
       "\n",
       "                                                              Dynamics Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           MLP   \n",
       "...                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 dynamics   \n",
       "\n",
       "                                                              Encoder Pre-training Task  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "...                                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "\n",
       "                                                              Encoder Pre-training Dataset  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "...                                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                          NaN   \n",
       "\n",
       "                                                              Encoder Pre-training Seed  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "...                                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "\n",
       "                                                              Encoder Training Task  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "...                                                                             ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  Image Reconstruction   \n",
       "\n",
       "                                                              Encoder Training Dataset  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "...                                                                                ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                   towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                   towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                no_towers   \n",
       "\n",
       "                                                              Encoder Training Seed  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "...                                                                             ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     0   \n",
       "\n",
       "                                                              Dynamics Training Task  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "...                                                                              ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...   Image Reconstruction   \n",
       "\n",
       "                                                              Dynamics Training Dataset  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             no_clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             no_clothiness   \n",
       "...                                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                 no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                 no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                 no_towers   \n",
       "\n",
       "                                                              Dynamics Training Seed  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "...                                                                              ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                      0   \n",
       "\n",
       "                                                                                                         ModelID  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "...                                                                                                          ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_tower...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_tower...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "\n",
       "                                                                                                      Model Kind  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "...                                                                                                          ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_same_...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_same_...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...   \n",
       "\n",
       "                                                              Visual encoder architecture  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "...                                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "\n",
       "                                                              Dynamics model architecture  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "...                                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "\n",
       "                                                              ObjectCentric  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "...                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...          True   \n",
       "\n",
       "                                                              Supervised  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "...                                                                  ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      False   \n",
       "\n",
       "                                                              SelfSupervisedLossSelfSupervisedLoss  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "...                                                                                            ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                                   NA   \n",
       "\n",
       "                                                              Encoder Training Dataset Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "...                                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                  all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                  all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                  all_but_this   \n",
       "\n",
       "                                                              Dynamics Training Dataset Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                            all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                            all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                            all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "...                                                                                      ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                           same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                           same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                   all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                   all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                   all_but_this   \n",
       "\n",
       "                                                              Readout Train Data Type  \n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "...                                                                               ...  \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                    same  \n",
       "\n",
       "[816 rows x 29 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_human_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Cohen's kappa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:30:51.034991Z",
     "iopub.status.busy": "2021-06-03T22:30:51.034463Z",
     "iopub.status.idle": "2021-06-03T22:35:20.911226Z",
     "shell.execute_reply": "2021-06-03T22:35:20.909848Z",
     "shell.execute_reply.started": "2021-06-03T22:30:51.034953Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file. Done!\n"
     ]
    }
   ],
   "source": [
    "out_dict = {}\n",
    "\n",
    "for scenario in sorted(MD['Readout Test Data'].unique()):\n",
    "    print(\"Now running scenario\",scenario)\n",
    "    _MD = MD[MD['Readout Test Data'] == scenario]\n",
    "    _HD = HD[HD['scenarioName'] == scenario]\n",
    "    for model in _MD['ModelID'].unique():\n",
    "        measures_for_model = []\n",
    "        #get responses of model        \n",
    "        _MD_model = _MD[_MD['ModelID'] == model]\n",
    "        _MD_model = _MD_model.sort_values('Canon Stimulus Name') #ensure same stim order\n",
    "        #iterate over the 100 or so participants\n",
    "        for gameID in _HD['gameID'].unique():\n",
    "            #get one game\n",
    "            _HD_game = _HD[_HD['gameID']==gameID]\n",
    "            #ensure stim order\n",
    "            _HD_game = _HD_game.sort_values('stim_ID')\n",
    "            #in case the models have more or less responses compared to humans\n",
    "            human_stim_names = list(_HD_game['stim_ID'])\n",
    "            model_stim_names = list(_MD_model['Canon Stimulus Name'])\n",
    "            joint_stim_names = set(human_stim_names).intersection(set(model_stim_names))\n",
    "            if len(joint_stim_names) == 0:\n",
    "                print(\"⛔️ {} is missing all datapoints on {} human responses\".format(model, len(human_stim_names)),end=\"\\r\")\n",
    "                continue #ignore and move on\n",
    "            if len(human_stim_names) > len(joint_stim_names):\n",
    "                print(\"⚠️ {} is missing {} datapoints on {} human responses\".format(model,len(human_stim_names) - len(joint_stim_names), len(human_stim_names)),end=\"\\r\")\n",
    "            #subset both models to ensure only common stims are used\n",
    "            _MD_model = _MD_model[_MD_model['Canon Stimulus Name'].isin(joint_stim_names)]            \n",
    "            _HD_game = _HD_game[_HD_game['stim_ID'].isin(joint_stim_names)]\n",
    "            #pull response vector\n",
    "            human_responses = np.array(_HD_game['responseBool'].astype(int)) #get human response and cast to int\n",
    "            model_responses = np.array(_MD_model['Predicted Outcome'])\n",
    "#             assert list(model_stim_names) == list(human_stim_names), \"experimental and test stims don't match\"\n",
    "            assert len(model_responses) == len(human_responses), \"More than 1 observation per stimulus\"\n",
    "            # compute Cohen's kappa\n",
    "            measure = sklearn.metrics.cohen_kappa_score(model_responses,human_responses)\n",
    "            measures_for_model.append(measure)\n",
    "        if len(measures_for_model) == 0:\n",
    "            print(\"⛔️ {} is missing all datapoints on human responses\".format(model))\n",
    "            continue\n",
    "        # get percentiles over the range of measures\n",
    "        lb = np.percentile(measures_for_model, 2.5)\n",
    "        med = np.percentile(measures_for_model, 50)\n",
    "        ub = np.percentile(measures_for_model, 97.5)\n",
    "        out_dict[(scenario, model)] = {**{'scenario':scenario,\n",
    "                                       'Cohens_k_lb':lb,\n",
    "                                       'Cohens_k_med':med,\n",
    "                                       'Cohens_k_ub':ub,\n",
    "                                        'num_datapoints':len(measures_for_model)},\n",
    "                                      **{col:_MD_model.head(1)[col].item() for col in MODEL_COLS+h.DATASET_ABSTRACTED_COLS} #save model ID info\n",
    "                                      }\n",
    "    clear_output(wait=True)\n",
    "\n",
    "model_human_CohensK = pd.DataFrame(out_dict).transpose()    \n",
    "model_human_CohensK.to_csv(os.path.join(csv_dir, 'summary','model_human_CohensK.csv'), index=False)\n",
    "print('Saved to file. Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:35:20.913624Z",
     "iopub.status.busy": "2021-06-03T22:35:20.913006Z",
     "iopub.status.idle": "2021-06-03T22:35:20.950072Z",
     "shell.execute_reply": "2021-06-03T22:35:20.949173Z",
     "shell.execute_reply.started": "2021-06-03T22:35:20.913581Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>Cohens_k_lb</th>\n",
       "      <th>Cohens_k_med</th>\n",
       "      <th>Cohens_k_ub</th>\n",
       "      <th>num_datapoints</th>\n",
       "      <th>Model</th>\n",
       "      <th>Readout Train Data</th>\n",
       "      <th>Readout Type</th>\n",
       "      <th>Encoder Type</th>\n",
       "      <th>Dynamics Type</th>\n",
       "      <th>Encoder Pre-training Task</th>\n",
       "      <th>Encoder Pre-training Dataset</th>\n",
       "      <th>Encoder Pre-training Seed</th>\n",
       "      <th>Encoder Training Task</th>\n",
       "      <th>Encoder Training Dataset</th>\n",
       "      <th>Encoder Training Seed</th>\n",
       "      <th>Dynamics Training Task</th>\n",
       "      <th>Dynamics Training Dataset</th>\n",
       "      <th>Dynamics Training Seed</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>Model Kind</th>\n",
       "      <th>Visual encoder architecture</th>\n",
       "      <th>Dynamics model architecture</th>\n",
       "      <th>ObjectCentric</th>\n",
       "      <th>Supervised</th>\n",
       "      <th>SelfSupervisedLossSelfSupervisedLoss</th>\n",
       "      <th>Encoder Training Dataset Type</th>\n",
       "      <th>Dynamics Training Dataset Type</th>\n",
       "      <th>Readout Train Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">clothiness</th>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all_readout_A_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>-0.0560903</td>\n",
       "      <td>0.059534</td>\n",
       "      <td>0.170113</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all_readout_B_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>-0.0899741</td>\n",
       "      <td>0.0561086</td>\n",
       "      <td>0.150315</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all_readout_C_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>-0.0899741</td>\n",
       "      <td>0.0367282</td>\n",
       "      <td>0.146167</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>C</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_clothiness_readout_A_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>-0.0605039</td>\n",
       "      <td>0.0609244</td>\n",
       "      <td>0.161099</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_clothiness_readout_B_clothiness_VGGFrozenMLP_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>-0.126677</td>\n",
       "      <td>0.00484221</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>75</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">towers</th>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_towers_Image Reconstruction_0_towers_readout_B_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>-0.0612147</td>\n",
       "      <td>0.0280737</td>\n",
       "      <td>0.122461</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_tower...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_same_...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_towers_Image Reconstruction_0_towers_readout_C_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>-0.0857314</td>\n",
       "      <td>0.0299138</td>\n",
       "      <td>0.118697</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_tower...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_same_...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_no_towers_Image Reconstruction_0_no_towers_readout_A_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>-0.0235696</td>\n",
       "      <td>0.101663</td>\n",
       "      <td>0.191503</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>A</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_no_towers_Image Reconstruction_0_no_towers_readout_B_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>-0.0616875</td>\n",
       "      <td>0.0175207</td>\n",
       "      <td>0.149518</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP3_OP3 encoder_0.0_Image Reconstruction_no_towers_Image Reconstruction_0_no_towers_readout_C_towers_OP3_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>-0.0738192</td>\n",
       "      <td>0.0320249</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>89</td>\n",
       "      <td>OP3</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>OP3 encoder</td>\n",
       "      <td>OP3 dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>Image Reconstruction</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_no_to...</td>\n",
       "      <td>OP3_OP3 encoder_0.0_Image Reconstruction_all_b...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 scenario  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  clothiness   \n",
       "...                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      towers   \n",
       "\n",
       "                                                              Cohens_k_lb  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  -0.0560903   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  -0.0899741   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  -0.0899741   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  -0.0605039   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   -0.126677   \n",
       "...                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  -0.0612147   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  -0.0857314   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  -0.0235696   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  -0.0616875   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  -0.0738192   \n",
       "\n",
       "                                                              Cohens_k_med  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...     0.059534   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...    0.0561086   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...    0.0367282   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...    0.0609244   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   0.00484221   \n",
       "...                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...    0.0280737   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...    0.0299138   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...     0.101663   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...    0.0175207   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...    0.0320249   \n",
       "\n",
       "                                                              Cohens_k_ub  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...    0.170113   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...    0.150315   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...    0.146167   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...    0.161099   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...    0.109616   \n",
       "...                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...    0.122461   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...    0.118697   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...    0.191503   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...    0.149518   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...    0.116395   \n",
       "\n",
       "                                                              num_datapoints  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             75   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             75   \n",
       "...                                                                      ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             89   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             89   \n",
       "\n",
       "                                                                      Model  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "...                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...           OP3   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...           OP3   \n",
       "\n",
       "                                                              Readout Train Data  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...         clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...         clothiness   \n",
       "...                                                                          ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...             towers   \n",
       "\n",
       "                                                              Readout Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...            A   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...            B   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...            C   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            A   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            B   \n",
       "...                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...            B   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...            C   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...            A   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...            B   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...            C   \n",
       "\n",
       "                                                              Encoder Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...          VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...          VGG   \n",
       "...                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 encoder   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 encoder   \n",
       "\n",
       "                                                              Dynamics Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           MLP   \n",
       "...                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 dynamics   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3 dynamics   \n",
       "\n",
       "                                                              Encoder Pre-training Task  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "...                                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "\n",
       "                                                              Encoder Pre-training Dataset  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "...                                                                                    ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                          NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                          NaN   \n",
       "\n",
       "                                                              Encoder Pre-training Seed  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "...                                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                       NaN   \n",
       "\n",
       "                                                              Encoder Training Task  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "...                                                                             ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  Image Reconstruction   \n",
       "\n",
       "                                                              Encoder Training Dataset  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "...                                                                                ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                   towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                   towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                no_towers   \n",
       "\n",
       "                                                              Encoder Training Seed  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "...                                                                             ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     0   \n",
       "\n",
       "                                                              Dynamics Training Task  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "...                                                                              ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...   Image Reconstruction   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...   Image Reconstruction   \n",
       "\n",
       "                                                              Dynamics Training Dataset  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                       all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             no_clothiness   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             no_clothiness   \n",
       "...                                                                                 ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                 no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                 no_towers   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                 no_towers   \n",
       "\n",
       "                                                              Dynamics Training Seed  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "...                                                                              ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                      0   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                      0   \n",
       "\n",
       "                                                                                                         ModelID  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_al...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "...                                                                                                          ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_tower...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_tower...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_no_to...   \n",
       "\n",
       "                                                                                                      Model Kind  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "...                                                                                                          ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_same_...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...  OP3_OP3 encoder_0.0_Image Reconstruction_same_...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...  OP3_OP3 encoder_0.0_Image Reconstruction_all_b...   \n",
       "\n",
       "                                                              Visual encoder architecture  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "...                                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "\n",
       "                                                              Dynamics model architecture  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "...                                                                                   ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                     Neither   \n",
       "\n",
       "                                                              ObjectCentric  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "...                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...          True   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...          True   \n",
       "\n",
       "                                                              Supervised  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "...                                                                  ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      False   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...      False   \n",
       "\n",
       "                                                              SelfSupervisedLossSelfSupervisedLoss  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "...                                                                                            ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                                   NA   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                                   NA   \n",
       "\n",
       "                                                              Encoder Training Dataset Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "...                                                                                     ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                          same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                  all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                  all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                  all_but_this   \n",
       "\n",
       "                                                              Dynamics Training Dataset Type  \\\n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                            all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                            all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                            all   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "...                                                                                      ...   \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                           same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                           same   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                   all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                   all_but_this   \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                   all_but_this   \n",
       "\n",
       "                                                              Readout Train Data Type  \n",
       "clothiness VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_all...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "...                                                                               ...  \n",
       "towers     OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_towers...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                    same  \n",
       "           OP3_OP3 encoder_0.0_Image Reconstruction_no_tow...                    same  \n",
       "\n",
       "[816 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_human_CohensK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model/human figure\n",
    "Results: Mega bar plot(s)/tables of model accuracies and human response correlations[Eli/Judy/Felix]. Models (~16) x Training (3) x Readout (3) x Target (2) x Scenarios (8) = 144 bars per model. That’s a lot! Needs careful thinking about how to display.\n",
    "\n",
    "Essentially outer y axis is scenario, outer x is measure (accuracy, correlation, Cohens kappa). Inner y for each square is the measure, inner x is models. Filled out dots are full procedure, not-filled out is without dynamics prediction. Humans are a zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===Very work in progress==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:35:20.951487Z",
     "iopub.status.busy": "2021-06-03T22:35:20.951235Z",
     "iopub.status.idle": "2021-06-03T22:35:20.989546Z",
     "shell.execute_reply": "2021-06-03T22:35:20.988965Z",
     "shell.execute_reply.started": "2021-06-03T22:35:20.951466Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>ratio</th>\n",
       "      <th>diff</th>\n",
       "      <th>human_correct</th>\n",
       "      <th>model_correct</th>\n",
       "      <th>Model</th>\n",
       "      <th>Readout Train Data</th>\n",
       "      <th>Readout Type</th>\n",
       "      <th>Encoder Type</th>\n",
       "      <th>Dynamics Type</th>\n",
       "      <th>Encoder Pre-training Task</th>\n",
       "      <th>Encoder Pre-training Dataset</th>\n",
       "      <th>Encoder Pre-training Seed</th>\n",
       "      <th>Encoder Training Task</th>\n",
       "      <th>Encoder Training Dataset</th>\n",
       "      <th>Encoder Training Seed</th>\n",
       "      <th>Dynamics Training Task</th>\n",
       "      <th>Dynamics Training Dataset</th>\n",
       "      <th>Dynamics Training Seed</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>Model Kind</th>\n",
       "      <th>Visual encoder architecture</th>\n",
       "      <th>Dynamics model architecture</th>\n",
       "      <th>ObjectCentric</th>\n",
       "      <th>Supervised</th>\n",
       "      <th>SelfSupervisedLossSelfSupervisedLoss</th>\n",
       "      <th>Encoder Training Dataset Type</th>\n",
       "      <th>Dynamics Training Dataset Type</th>\n",
       "      <th>Readout Train Data Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">clothiness</th>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_all_readout_A_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>1.0152</td>\n",
       "      <td>0.0103089</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_all_readout_B_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.792895</td>\n",
       "      <td>-0.140445</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.537688</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_all_Contrastive_0_all_readout_C_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>-0.170596</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>C</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_clothiness_Contrastive_0_clothiness_readout_A_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.874407</td>\n",
       "      <td>-0.0851685</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>A</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_same_Contras...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSWM_CSWM encoder_0.0_Contrastive_clothiness_Contrastive_0_clothiness_readout_B_clothiness_CSWM_results.csv</th>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.785485</td>\n",
       "      <td>-0.14547</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>0.532663</td>\n",
       "      <td>CSWM</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>B</td>\n",
       "      <td>CSWM encoder</td>\n",
       "      <td>CSWM dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>Contrastive</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...</td>\n",
       "      <td>CSWM_CSWM encoder_0.0_Contrastive_same_Contras...</td>\n",
       "      <td>Neither</td>\n",
       "      <td>Neither</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">towers</th>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_towers_readout_B_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.838863</td>\n",
       "      <td>-0.12297</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.640167</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_towers_readout_C_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>-0.102049</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.661088</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>no_towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all_but_this</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_towers_readout_A_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.970449</td>\n",
       "      <td>-0.0225515</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>A</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_towers_readout_B_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.816932</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.623431</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>B</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_towers_readout_C_towers_VGGFrozenMLP_results.csv</th>\n",
       "      <td>towers</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>-0.135522</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.627615</td>\n",
       "      <td>VGGFrozenMLP</td>\n",
       "      <td>towers</td>\n",
       "      <td>C</td>\n",
       "      <td>VGG</td>\n",
       "      <td>MLP</td>\n",
       "      <td>ImageNet classification</td>\n",
       "      <td>ImageNet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L2 on latent</td>\n",
       "      <td>towers</td>\n",
       "      <td>0</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...</td>\n",
       "      <td>VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 scenario  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  clothiness   \n",
       "...                                                                   ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      towers   \n",
       "\n",
       "                                                                  ratio  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...    1.0152   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  0.792895   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  0.748433   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  0.874407   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  0.785485   \n",
       "...                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.838863   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  0.866276   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  0.970449   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  0.816932   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  0.822414   \n",
       "\n",
       "                                                                    diff  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  0.0103089   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  -0.140445   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  -0.170596   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co... -0.0851685   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...   -0.14547   \n",
       "...                                                                  ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   -0.12297   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  -0.102049   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow... -0.0225515   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  -0.139706   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  -0.135522   \n",
       "\n",
       "                                                              human_correct  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.678133   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.678133   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.763137   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.763137   \n",
       "\n",
       "                                                              model_correct  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.688442   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.537688   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      0.507538   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.592965   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      0.532663   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.640167   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      0.661088   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.740586   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.623431   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      0.627615   \n",
       "\n",
       "                                                                      Model  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          CSWM   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          CSWM   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP   \n",
       "\n",
       "                                                              Readout Train Data  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...         clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...         clothiness   \n",
       "...                                                                          ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...             towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...             towers   \n",
       "\n",
       "                                                              Readout Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            A   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            B   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            C   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            A   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            B   \n",
       "...                                                                    ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            B   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            C   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            A   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            B   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            C   \n",
       "\n",
       "                                                               Encoder Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM encoder   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM encoder   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           VGG   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           VGG   \n",
       "\n",
       "                                                               Dynamics Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM dynamics   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM dynamics   \n",
       "...                                                                      ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...            MLP   \n",
       "\n",
       "                                                              Encoder Pre-training Task  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "...                                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   ImageNet classification   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   ImageNet classification   \n",
       "\n",
       "                                                              Encoder Pre-training Dataset  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          NaN   \n",
       "...                                                                                    ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                     ImageNet   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                     ImageNet   \n",
       "\n",
       "                                                              Encoder Pre-training Seed  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                       NaN   \n",
       "...                                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                       NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                       NaN   \n",
       "\n",
       "                                                              Encoder Training Task  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...           Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...           Contrastive   \n",
       "...                                                                             ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "\n",
       "                                                              Encoder Training Dataset  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...               clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...               clothiness   \n",
       "...                                                                                ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      NaN   \n",
       "\n",
       "                                                              Encoder Training Seed  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     0   \n",
       "...                                                                             ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                   NaN   \n",
       "\n",
       "                                                              Dynamics Training Task  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            Contrastive   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...            Contrastive   \n",
       "...                                                                              ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           L2 on latent   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           L2 on latent   \n",
       "\n",
       "                                                              Dynamics Training Dataset  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                       all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                clothiness   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                clothiness   \n",
       "...                                                                                 ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 no_towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 no_towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    towers   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    towers   \n",
       "\n",
       "                                                              Dynamics Training Seed  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                      0   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                      0   \n",
       "...                                                                              ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      0   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                      0   \n",
       "\n",
       "                                                                                                         ModelID  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_clothiness_C...   \n",
       "...                                                                                                          ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...  VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_to...   \n",
       "\n",
       "                                                                                                      Model Kind  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...  CSWM_CSWM encoder_0.0_Contrastive_all_Contrast...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_same_Contras...   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...  CSWM_CSWM encoder_0.0_Contrastive_same_Contras...   \n",
       "...                                                                                                          ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...   VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_same   \n",
       "\n",
       "                                                              Visual encoder architecture  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "...                                                                                   ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                 Transformer   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                 Transformer   \n",
       "\n",
       "                                                              Dynamics model architecture  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                     Neither   \n",
       "...                                                                                   ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                         MLP   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                         MLP   \n",
       "\n",
       "                                                              ObjectCentric  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          True   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...          True   \n",
       "...                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...           NaN   \n",
       "\n",
       "                                                              Supervised  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      False   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...      False   \n",
       "...                                                                  ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      False   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...      False   \n",
       "\n",
       "                                                              SelfSupervisedLossSelfSupervisedLoss  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                                   NA   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                                   NA   \n",
       "...                                                                                            ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                                   NA   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                                   NA   \n",
       "\n",
       "                                                              Encoder Training Dataset Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                           all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                           all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                           all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          same   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                          same   \n",
       "...                                                                                     ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           NaN   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           NaN   \n",
       "\n",
       "                                                              Dynamics Training Dataset Type  \\\n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                            all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                            all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                            all   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                           same   \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                           same   \n",
       "...                                                                                      ...   \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                   all_but_this   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           same   \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                           same   \n",
       "\n",
       "                                                              Readout Train Data Type  \n",
       "clothiness CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_all_Contrasti...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                    same  \n",
       "           CSWM_CSWM encoder_0.0_Contrastive_clothiness_Co...                    same  \n",
       "...                                                                               ...  \n",
       "towers     VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_no_...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    same  \n",
       "           VGGFrozenMLP_VGG_nan_nan_nan_L2 on latent_0_tow...                    same  \n",
       "\n",
       "[816 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_human_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:35:20.991202Z",
     "iopub.status.busy": "2021-06-03T22:35:20.990820Z",
     "iopub.status.idle": "2021-06-03T22:35:21.003853Z",
     "shell.execute_reply": "2021-06-03T22:35:21.003166Z",
     "shell.execute_reply.started": "2021-06-03T22:35:20.991166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all_but_this', 'all', 'same'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD['Dynamics Training Dataset Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:35:21.005799Z",
     "iopub.status.busy": "2021-06-03T22:35:21.005461Z",
     "iopub.status.idle": "2021-06-03T22:35:21.011114Z",
     "shell.execute_reply": "2021-06-03T22:35:21.009729Z",
     "shell.execute_reply.started": "2021-06-03T22:35:21.005776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "READOUTS = [(\"C\",\"full\"),\n",
    "            (\"B\",\"none\")]\n",
    "\n",
    "TRAININGS = [\n",
    "    ('all_but_this',\"^\"),\n",
    "    ('all',\"s\"),\n",
    "    ('same',\"o\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T22:35:21.013253Z",
     "iopub.status.busy": "2021-06-03T22:35:21.012659Z",
     "iopub.status.idle": "2021-06-03T22:35:21.017144Z",
     "shell.execute_reply": "2021-06-03T22:35:21.016137Z",
     "shell.execute_reply.started": "2021-06-03T22:35:21.013213Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set up color map over models\n",
    "from matplotlib import cm\n",
    "\n",
    "#cmap = cm.tab20.colors ## not enough colors\n",
    "turbo = cm.get_cmap('turbo', 22)\n",
    "cmap = turbo(np.linspace(0, 1, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-04T00:06:21.450067Z",
     "iopub.status.busy": "2021-06-04T00:06:21.449790Z",
     "iopub.status.idle": "2021-06-04T00:06:36.068268Z",
     "shell.execute_reply": "2021-06-04T00:06:36.067580Z",
     "shell.execute_reply.started": "2021-06-04T00:06:21.450029Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(MD['Readout Test Data'].unique()),3, figsize=(40,40), sharex=True, sharey=False)\n",
    "\n",
    "models = sorted(MD['Model Kind'].unique())\n",
    "\n",
    "for outer_y, scenario in enumerate(sorted(MD['Readout Test Data'].unique())):\n",
    "    # ———accuracy plot———\n",
    "    axis = axes[outer_y,0]\n",
    "    axis.set_title(scenario + \" accuracy\")\n",
    "    #plot human zone\n",
    "    human_row = human_bootstrapped_accuracy[human_bootstrapped_accuracy['scenario'] == scenario]\n",
    "    lb = float(human_row['ci_lb'])\n",
    "    ub = float(human_row['ci_ub'])\n",
    "    mean = float(human_row['obs_mean'])\n",
    "    axis.axhspan(lb,ub,color=(.8,.9,1))\n",
    "    axis.set_xticks(np.arange(len(models)))\n",
    "    axis.set_xticklabels(models,rotation=90)\n",
    "    \n",
    "    #plot models\n",
    "    for x,model in enumerate(models):\n",
    "        #get relevant rows\n",
    "        rows = model_human_accuracies[(model_human_accuracies['Model Kind'] == model) & (model_human_accuracies['scenario'] == scenario)]\n",
    "        for readout,fill in READOUTS:\n",
    "            for i,(training,symbol) in enumerate(TRAININGS):\n",
    "                row = rows[(rows['Readout Type']==readout) & (rows['Dynamics Training Dataset Type'] == training)]\n",
    "                if len(row) > 0: #do we have something to plot?\n",
    "                    assert len(row) == 1, \"More than one entry for specific agent\"\n",
    "                    lb = row['model_correct']\n",
    "                    ub = row['model_correct']\n",
    "                    measure = row['model_correct']\n",
    "                    ub = abs(ub - measure)\n",
    "                    lb = abs(lb - measure)\n",
    "                    axis.errorbar(x+(i*.333)+(fill==\"none\")*.166,measure,(lb,ub),marker=symbol,fillstyle=fill,label=model,color=cmap[x])\n",
    "        axis.set_ybound([0,1])\n",
    "    \n",
    "    # ———correlation plot———\n",
    "    axis = axes[outer_y,1]\n",
    "    axis.set_title(scenario + \" correlation\")\n",
    "    #plot human zone\n",
    "    human_row = human_boot_corr[human_boot_corr['scenario'] == scenario]\n",
    "    lb = float(human_row['corr_lb'])\n",
    "    ub = float(human_row['corr_ub'])\n",
    "    mean = float(human_row['corr_med'])\n",
    "    axis.axhspan(lb,ub,color=(.8,.9,1))\n",
    "    axis.set_xticks(np.arange(len(models)))\n",
    "    axis.set_xticklabels(models,rotation=90)\n",
    "\n",
    "    #plot models\n",
    "    for x,model in enumerate(models):\n",
    "        #get relevant rows\n",
    "        rows = model_human_correlations[(model_human_correlations['Model Kind'] == model) & (model_human_correlations['scenario'] == scenario)]\n",
    "        for readout,fill in READOUTS:\n",
    "            for i,(training,symbol) in enumerate(TRAININGS):\n",
    "                row = rows[(rows['Readout Type']==readout) & (rows['Dynamics Training Dataset Type'] == training)]\n",
    "                if len(row) > 0: #do we have something to plot?\n",
    "                    assert len(row) == 1, \"More than one entry for specific agent\"\n",
    "                    lb = row['corr_lb']\n",
    "                    ub = row['corr_ub']\n",
    "                    measure = row['corr_med']\n",
    "                    ub = abs(ub - measure)\n",
    "                    lb = abs(lb - measure)\n",
    "                    axis.errorbar(x+(i*.333)+(fill==\"none\")*.166,measure,(lb,ub),marker=symbol,fillstyle=fill,label=model,color=cmap[x])\n",
    "        axis.set_ybound([0,1])\n",
    "        \n",
    "    \n",
    "    # ———Cohens'k plot———\n",
    "    axis = axes[outer_y,2]\n",
    "    axis.set_title(scenario + \" Cohen's kappa\")\n",
    "    #plot human zone\n",
    "    human_row = human_boot_cohenk[human_boot_cohenk['scenario'] == scenario]\n",
    "    lb = float(human_row['corr_lb'])\n",
    "    ub = float(human_row['corr_ub'])\n",
    "    mean = float(human_row['corr_med'])\n",
    "    axis.axhspan(lb,ub,color=(.8,.9,1))\n",
    "    axis.set_xticks(np.arange(len(models)))\n",
    "    axis.set_xticklabels(models,rotation=90)\n",
    "\n",
    "    #plot models\n",
    "    for x,model in enumerate(models):\n",
    "        #get relevant rows\n",
    "        rows = model_human_CohensK[(model_human_CohensK['Model Kind'] == model) & (model_human_CohensK['scenario'] == scenario)]\n",
    "        for readout,fill in READOUTS:\n",
    "            for i,(training,symbol) in enumerate(TRAININGS):\n",
    "                row = rows[(rows['Readout Type']==readout) & (rows['Dynamics Training Dataset Type'] == training)]\n",
    "                if len(row) > 0: #do we have something to plot?\n",
    "                    assert len(row) == 1, \"More than one entry for specific agent\"\n",
    "                    lb = row['Cohens_k_lb']\n",
    "                    ub = row['Cohens_k_ub']\n",
    "                    measure = row['Cohens_k_med']\n",
    "                    ub = abs(ub - measure)\n",
    "                    lb = abs(lb - measure)\n",
    "                    axis.errorbar(x+(i*.333)+(fill==\"none\")*.166,measure,(lb,ub),marker=symbol,fillstyle=fill,color=cmap[x])\n",
    "        axis.set_ybound([-.25\n",
    "                         ,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
