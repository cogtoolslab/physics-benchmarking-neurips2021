{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of human and model behavior across physical domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this notebook is to:** \n",
    "* Apply preprocessing to human behavioral data\n",
    "* Visualize distribution and compute summary statistics over **human** physical judgments\n",
    "* Visualize distribution and compute summary statistics over **model** physical judgments\n",
    "* Conduct human-model comparisons\n",
    "* Output CSV that can be re-loaded into R notebook for statistical modeling & fancy visualizations\n",
    "\n",
    "**This notebook depends on:**\n",
    "* Running `./generate_dataframes.py` (INTERNAL USE ONLY)\n",
    "* Running `./upload_results.py` (INTERNAL USE ONLY)\n",
    "* Running `./download_results.py` (PUBLIC USE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "sys.path.append('./analysis_helpers')\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# seaborn plotting themes\n",
    "sns.set_context('talk')\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up paths and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(analysis_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(analysis_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>bucket_name</th>\n",
       "      <th>stim_version</th>\n",
       "      <th>iterationName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dominoes_pilot</td>\n",
       "      <td>human-physics-benchmarking-dominoes-pilot</td>\n",
       "      <td>production_1</td>\n",
       "      <td>production_1_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>collision_pilot</td>\n",
       "      <td>human-physics-benchmarking-collision-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>towers_pilot</td>\n",
       "      <td>human-physics-benchmarking-towers-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linking_pilot</td>\n",
       "      <td>human-physics-benchmarking-linking-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>containment_pilot</td>\n",
       "      <td>human-physics-benchmarking-containment-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rollingsliding_pilot</td>\n",
       "      <td>human-physics-benchmarking-rollingsliding-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drop_pilot</td>\n",
       "      <td>human-physics-benchmarking-drop-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clothiness_pilot</td>\n",
       "      <td>human-physics-benchmarking-clothiness-pilot</td>\n",
       "      <td>production_2</td>\n",
       "      <td>production_2_testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  study                                      bucket_name  \\\n",
       "0        dominoes_pilot        human-physics-benchmarking-dominoes-pilot   \n",
       "1       collision_pilot       human-physics-benchmarking-collision-pilot   \n",
       "2          towers_pilot          human-physics-benchmarking-towers-pilot   \n",
       "3         linking_pilot         human-physics-benchmarking-linking-pilot   \n",
       "4     containment_pilot     human-physics-benchmarking-containment-pilot   \n",
       "5  rollingsliding_pilot  human-physics-benchmarking-rollingsliding-pilot   \n",
       "6            drop_pilot            human-physics-benchmarking-drop-pilot   \n",
       "7      clothiness_pilot      human-physics-benchmarking-clothiness-pilot   \n",
       "\n",
       "   stim_version         iterationName  \n",
       "0  production_1  production_1_testing  \n",
       "1  production_2  production_2_testing  \n",
       "2  production_2  production_2_testing  \n",
       "3  production_2  production_2_testing  \n",
       "4  production_2  production_2_testing  \n",
       "5  production_2  production_2_testing  \n",
       "6  production_2  production_2_testing  \n",
       "7  production_2  production_2_testing  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from experiment_meta import *\n",
    "HEM = pd.DataFrame(NEURIPS2021_EXPS) # HEM = \"human experiment metadata\"\n",
    "HEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get paths to all human response data\n",
    "data_paths = [os.path.join(csv_dir,'humans',i) for i in os.listdir(os.path.join(csv_dir,'humans'))]\n",
    "resp_paths = [i for i in data_paths if i.split('/')[-1].split('-')[0]=='human_responses']\n",
    "assert len(resp_paths)==8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate summary table of human 95% CIs for accuracy across all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently analyzing the collision experiment.\n",
      "Currently analyzing the rollingsliding experiment.\n",
      "Currently analyzing the dominoes experiment.\n",
      "Currently analyzing the drop experiment.\n",
      "Currently analyzing the clothiness experiment.\n",
      "Currently analyzing the linking experiment.\n",
      "Currently analyzing the containment experiment.\n",
      "Currently analyzing the towers experiment.\n"
     ]
    }
   ],
   "source": [
    "import analysis_helpers as h\n",
    "\n",
    "## init bootAcc for plotting\n",
    "bootAcc = pd.DataFrame()\n",
    "\n",
    "for exp_ind, exp_name in enumerate(resp_paths):\n",
    "    \n",
    "    ## get path to response data\n",
    "    path_to_data = resp_paths[exp_ind]\n",
    "\n",
    "    ## load data and apply preprocessing\n",
    "    _D = h.load_and_preprocess_data(path_to_data)\n",
    "    scenarioName = _D.scenarioName.values[0]\n",
    "    print('Currently analyzing the {} experiment.'.format(_D.scenarioName.values[0]))\n",
    "\n",
    "    ## apply exclusion criteria\n",
    "    D = h.apply_exclusion_criteria(_D)\n",
    "\n",
    "    ## compute bootstrapped sampling distributions of accuracy\n",
    "    Dacc = D.groupby('prolificIDAnon').agg({'correct':np.mean})\n",
    "    bootmeans = h.bootstrap_mean(Dacc, col='correct', nIter=1000)\n",
    "\n",
    "    obsmean = np.mean(Dacc.correct.values)\n",
    "    bootmean = np.mean(bootmeans)\n",
    "    lb = np.percentile(bootmeans,2.5)\n",
    "    ub = np.percentile(bootmeans,97.5)\n",
    "    \n",
    "    ## merge bootstrapped accuracy estimates\n",
    "    if len(bootAcc)==0:\n",
    "        bootAcc = pd.DataFrame(['human', scenarioName, obsmean,bootmean,lb,ub]).transpose()\n",
    "    else:\n",
    "        bootAcc = pd.concat([bootAcc, pd.DataFrame(['human', scenarioName, obsmean,bootmean,lb,ub]).transpose()],axis=0)\n",
    "        \n",
    "## add column names        \n",
    "bootAcc.columns=['agent','scenario','obs_mean', 'boot_mean', 'ci_lb', 'ci_ub']\n",
    "\n",
    "## save out bootAcc to re-plot in R\n",
    "if not os.path.exists(os.path.join(csv_dir, 'summary')):\n",
    "    os.makedirs(os.path.join(csv_dir, 'summary'))    \n",
    "bootAcc.to_csv(os.path.join(csv_dir, 'summary','human_accuracy_by_scenario.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>scenario</th>\n",
       "      <th>obs_mean</th>\n",
       "      <th>boot_mean</th>\n",
       "      <th>ci_lb</th>\n",
       "      <th>ci_ub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>collision</td>\n",
       "      <td>0.807333</td>\n",
       "      <td>0.807273</td>\n",
       "      <td>0.79748</td>\n",
       "      <td>0.816963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>rollingsliding</td>\n",
       "      <td>0.882986</td>\n",
       "      <td>0.882948</td>\n",
       "      <td>0.875411</td>\n",
       "      <td>0.890696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>dominoes</td>\n",
       "      <td>0.690989</td>\n",
       "      <td>0.690911</td>\n",
       "      <td>0.682634</td>\n",
       "      <td>0.699048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>drop</td>\n",
       "      <td>0.743656</td>\n",
       "      <td>0.743722</td>\n",
       "      <td>0.73541</td>\n",
       "      <td>0.751326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>clothiness</td>\n",
       "      <td>0.679394</td>\n",
       "      <td>0.679202</td>\n",
       "      <td>0.663331</td>\n",
       "      <td>0.693639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>linking</td>\n",
       "      <td>0.643182</td>\n",
       "      <td>0.643234</td>\n",
       "      <td>0.631968</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>containment</td>\n",
       "      <td>0.766988</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.758072</td>\n",
       "      <td>0.775026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>towers</td>\n",
       "      <td>0.763137</td>\n",
       "      <td>0.763012</td>\n",
       "      <td>0.754975</td>\n",
       "      <td>0.770982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent        scenario  obs_mean boot_mean     ci_lb     ci_ub\n",
       "0  human       collision  0.807333  0.807273   0.79748  0.816963\n",
       "0  human  rollingsliding  0.882986  0.882948  0.875411  0.890696\n",
       "0  human        dominoes  0.690989  0.690911  0.682634  0.699048\n",
       "0  human            drop  0.743656  0.743722   0.73541  0.751326\n",
       "0  human      clothiness  0.679394  0.679202  0.663331  0.693639\n",
       "0  human         linking  0.643182  0.643234  0.631968  0.654545\n",
       "0  human     containment  0.766988  0.766892  0.758072  0.775026\n",
       "0  human          towers  0.763137  0.763012  0.754975  0.770982"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human accuracy across stimuli for each participant\n",
    "We will analyze accuracy for each participant by computing the proportion of correct responses across all stimuli. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = D.groupby('stim_ID').agg({'correct':np.mean})\n",
    "p = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-human consistency for each stimulus\n",
    "We will estimate human-human consistency for each stimulus by computing the proportion of responses that match the modal response for that stimulus (whether that modal response is correct or incorrect).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(np.unique(D.groupby('stim_ID').agg({'correct':'count'})['correct'].values))==1 # sanity check\n",
    "numSubs = np.unique(D.groupby('stim_ID').agg({'correct':'count'})['correct'].values)[0] # get num subs\n",
    "Dmode = D.groupby('stim_ID').agg({'responseBool':scipy.stats.mode}) # compute modal response\n",
    "propModalResponse = Dmode['responseBool'].apply(lambda x: x[1][0]).values / numSubs # get proportion modal response\n",
    "Dmode = Dmode.assign(propModalResponse = Dmode['responseBool'].apply(lambda x: x[1][0]).values / numSubs) \n",
    "Dcombined = Dacc.merge(Dmode, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.histplot(data=Dmode, x='propModalResponse', bins=30, stat='probability')\n",
    "t = plt.title('Distribution of agreement among participants (similar to above, but not exactly the same)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-human consistency across stimuli (within scenario)\n",
    "We will analyze human-human consistency by computing the mean correlation between (binary) response vectors produced by each human participant across all stimuli within each scenario. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create response feature matrix (numSubs x numTrialsPerSub)\n",
    "D2 = D.sort_values(by=['prolificIDAnon','stim_ID']).reset_index(drop=True)\n",
    "numSubs = len(np.unique(D['prolificIDAnon'].values))\n",
    "numTrialsPerSub = int(len(D)/numSubs)\n",
    "respMat = np.reshape(D2['responseBool'].values, (numSubs,numTrialsPerSub)) \n",
    "\n",
    "## sanity check that the reshape operation happened correctly\n",
    "assert len([i for (i,j) in list(zip(respMat[0],D2[:150]['responseBool'].values)) if i!=j])==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get pairwise correlation distances\n",
    "dists = scipy.spatial.distance.pdist(respMat, metric='correlation')\n",
    "corrMat = scipy.spatial.distance.squareform(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## distribution of pairwise correlations between participant response vectors\n",
    "p = sns.histplot(corrMat[np.triu_indices(n=len(corrMat), k=1)])\n",
    "t = plt.title('pairwise correlations between participant response vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwiseCorrs = corrMat[np.triu_indices(n=len(corrMat), k=1)]\n",
    "lb = np.percentile(pairwiseCorrs, 2.5)\n",
    "ub = np.percentile(pairwiseCorrs, 97.5)\n",
    "print('The median pairwise correlation is {}.'.format(np.percentile(pairwiseCorrs, 50).round(3)))\n",
    "print('95% CI: [{},{}].'.format(lb.round(3),ub.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot heatmap of correlation distances between participants\n",
    "reallyRun = False\n",
    "if reallyRun:\n",
    "    sns.heatmap(corrMat, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human accuracy as a function of stimulus attributes\n",
    "We will conduct exploratory analyses of human accuracy as a function of various scenario-specific stimulus attributes that varied across trials. We will examine those stimulus attributes that varied across stimuli within each scenario and explore the relationship between each individual attribute and human accuracy, as well as beetween linear combinations of them and human accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human accuracy by scenario\n",
    "We will fit human responses across all scenarios with a mixed-effects logistic regression model, including scenario as a fixed effect and participants and individual stimuli as random effects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other exploratory human behavioral analyses\n",
    "* We will explore the relation of demographic variables on the performance of participants: how does age, gender, educational status and the the result of a one-trial spatial reasoning task relate to the overall accuracy of a subject?\n",
    "* We will additionally explore any potential left/right or yes/no response biases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution of model physical judgments, by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute summary statistics over model physical judgments, by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct human-model comparisons\n",
    "We will compare human and model behavior in two ways: **absolute performance** and **response pattern.**\n",
    "\n",
    "#### **Absolute Performance** \n",
    "We will compare the accuracy of each model to the mean accuracy of humans, for each scenario. \n",
    "To do this, we will first compute estimates of mean human accuracy for each scenario and construct 95% confidence intervals for each of these estimates. \n",
    "These confidence intervals will be constructed by bootstrapping: specifically, for an experiment with N participants, we will resample N participants with replacement and compute the proportion correct for that bootstrapped sample. We will take repeat this resampling procedure 1000 times to generate a sampling distribution for the mean proportion correct. The 2.5th and 97.5th percentile will be extracted from this sampling distribution to provide the lower and upper bounds of the 95% confidence interval.\n",
    "\n",
    "For each model, we will then compare their proportion correct (a point estimate) to the human confidence interval. \n",
    "\n",
    "#### **Response Pattern**\n",
    "We will compare the pattern of predictions generated by each model to the pattern of predictions generated by humans. \n",
    "\n",
    "We will do this by using two standard inter-rater reliability metrics:\n",
    "##### **Correlation**\n",
    "For each pair of human participants, we will compute the correlation between their (binary) response vectors, yielding a distribution of pairwise human-human correlations. \n",
    "For each model, we will compute the correlation between its response vector and every human participant, as well as every other model. \n",
    "A model's response pattern will be considered more similar to humans' insofar as the mean model-human correlation (across humans) lies closer to the mean human-human correlation (for all pairs of humans).\n",
    "\n",
    "##### **Cohen's kappa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
