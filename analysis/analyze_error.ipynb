{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of human error rate under different experiment parameters across scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this notebook is to:** \n",
    "* Apply preprocessing to human behavioral data\n",
    "* Visualize distribution and compute summary statistics over **human** physical judgments\n",
    "* Conduct error analysis on which scenarios/ instances did humans make lots of error\n",
    "* Conduct more detailed error analysis on which scenarios/ instances did humans and models diverge the most\n",
    "\n",
    "**This notebook depends on:**\n",
    "* Running `./download_results.py` (PUBLIC USE)\n",
    "* Download all mp4 files from this [link](https://physics-benchmarking-neurips2021-dataset.s3.amazonaws.com/Physion.zip) and put them into the `./result/videos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib, io\n",
    "\n",
    "sys.path.append('./analysis_helpers')\n",
    "from importlib import reload\n",
    "from analysis_helpers import *\n",
    "from display_trials import *\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "from IPython.display import Video\n",
    "from ipywidgets import Output, GridspecLayout\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont \n",
    "\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# seaborn plotting themes\n",
    "sns.set_context('talk')\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up paths and directoriesg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "datavol_dir = os.path.join(proj_dir,'data')\n",
    "analysis_dir =  os.path.abspath('.')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "video_dir = os.path.join(results_dir,'videos')\n",
    "json_dir = os.path.join(results_dir,'json')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'behavioral_experiments'))\n",
    "png_dir = os.path.abspath(os.path.join(datavol_dir,'png'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'stimuli'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)   \n",
    "    \n",
    "if not os.path.exists(video_dir):\n",
    "    os.makedirs(video_dir) \n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(analysis_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(analysis_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_meta import *\n",
    "HEM = pd.DataFrame(NEURIPS2021_EXPS) # HEM = \"human experiment metadata\"\n",
    "HEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get paths to all human response data\n",
    "data_paths = [os.path.join(csv_dir,'humans',i) for i in os.listdir(os.path.join(csv_dir,'humans'))]\n",
    "resp_paths = [i for i in data_paths if i.split('/')[-1].split('-')[0]=='human_responses']\n",
    "assert len(resp_paths)==8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in example dataframe\n",
    "exp_ind = 0\n",
    "d = pd.concat([pd.read_csv(p) for p in resp_paths])\n",
    "\n",
    "## some utility vars\n",
    "d['scenarioName'] = d['study'].apply(lambda x:x.split('_')[0])\n",
    "# colnames_with_variable_entries = [col for col in sorted(d.columns) if len(np.unique(d[col]))>1]\n",
    "colnames = ['scenarioName','study','gameID','trialNum','prolificIDAnon','stim_ID','response','target_hit_zone_label','correct','choices','rt']\n",
    "# colnames = ['gameID','trialNum','stim_ID','response','target_hit_zone_label','correct','choices','rt']\n",
    "\n",
    "## subset dataframe by colnames of interest\n",
    "_D = d[colnames]\n",
    "\n",
    "## preprocess RTs (subtract 2500ms presentation time, log transform)\n",
    "_D = _D.assign(RT = _D['rt'] - 2500) \n",
    "_D = _D.assign(logRT = np.log(_D['RT']))\n",
    "_D = _D.drop(columns=['rt'],axis=1)\n",
    "\n",
    "## convert responses to boolean\n",
    "binary_mapper = {'YES':True, 'NO':False}\n",
    "_D = _D.assign(responseBool = _D['response'].apply(lambda x: binary_mapper[x]), axis=0)\n",
    "\n",
    "# print('Currently analyzing the {} experiment.'.format(scenarioName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exclusion criteria (from `preregistration_neurips2021.md`)\n",
    "\n",
    " Data from an entire experimental session will be excluded if the responses:\n",
    " * contain a sequence with unusually long streak, defined as occurring less than 2.5% of the time under random responding\n",
    " * contain a sequence of at least 24 trials alternating \"yes\" and \"no\" responses\n",
    " * are correct for fewer than 4 out of 10 familiarization trials (i.e., 30% correct or lower)\n",
    " * the mean accuracy for that participant is below 3 standard deviations below the median accuracy across all participants \\for that scenario\n",
    " * the mean log-transformed response time for that participant is 3 standard deviations above the median log-transformed response time across all participants for that scenario\n",
    " \n",
    "Excluded sessions will be flagged. Flagged sessions will not be included in the main analyses. We will also conduct our planned analyses with the flagged sessions included to investigate the extent to which the outcomes of the main analyses change when these sessions are included. Specifically, we will fit a statistical model to all sessions and estimate the effect of a session being flagged on accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_helpers import *\n",
    "D = apply_exclusion_criteria(_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution and compute summary statistics over human physical judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human accuracy by scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dominoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "dominoes = D[D[\"scenarioName\"] == \"dominoes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the accuracy dsitribution\n",
    "Dacc = dominoes.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for dominoes')\n",
    "\n",
    "Dacc['answer'] = dominoes.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- Total/ bad occlusion\n",
    "- Block stuck at weird positions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "support = D[D[\"scenarioName\"] == \"towers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = support.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for tower')\n",
    "\n",
    "Dacc['answer'] = support.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "collide = D[D[\"scenarioName\"] == \"collision\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = collide.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for collison')\n",
    "\n",
    "Dacc['answer'] = collide.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "contain = D[D[\"scenarioName\"] == \"containment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = contain.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for tower')\n",
    "\n",
    "Dacc['answer'] = contain.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc[Dacc[\"correct\"]<=0.33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Physics broke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "drop = D[D[\"scenarioName\"] == \"drop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = drop.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for drop')\n",
    "\n",
    "Dacc['answer'] = drop.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "link = D[D[\"scenarioName\"] == \"linking\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = link.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for linking')\n",
    "\n",
    "Dacc['answer'] = link.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dominoes trials\n",
    "roll = D[D[\"scenarioName\"] == \"rollingsliding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = roll.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for rolling & sliding')\n",
    "\n",
    "Dacc['answer'] = roll.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all drape trials\n",
    "drape = D[D[\"scenarioName\"] == \"clothiness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3%/ 66.7%/ 100% Accuracy Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dacc = drape.groupby('stim_ID').agg({'correct':np.mean})\n",
    "h = sns.histplot(data=Dacc, x='correct', bins=30, stat='probability')\n",
    "t = plt.title('Accuracy distribution across stimuli for drape')\n",
    "\n",
    "Dacc['answer'] = drape.groupby('stim_ID')['target_hit_zone_label'].first() # add ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (a) systematically fail (0 <= p <= 33.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the trails with accuracies lower than 33.3%\n",
    "\n",
    "plot_by_3(Dacc, video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problematic instances with low accuracy:\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (b) are close to chance (33.3% < p <= 66.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (c) consistently succeed (66.7% < p <= 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of exeriment parameters that are problematic. \n",
    "- Dominoes\n",
    "    - Bad occlusion (can't see any domino, or portion important for inference is blocked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
