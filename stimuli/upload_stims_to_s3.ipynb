{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload video stimuli to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Which experiment? bucket_name is the name of the experiment and will be name of the databases both on mongoDB and S3\n",
    "bucket_name = 'human-physics-benchmarking-XXX-pilot' #CHANGE THIS ⚡️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_files(paths, ext='mp4'):\n",
    "    \"\"\"Pass list of folders if there are stimuli in multiple folders. \n",
    "    Make sure that the containing folder is informative, as the rest of the path is ignored in naming. \n",
    "    Also returns filenames as uploaded to S3\"\"\"\n",
    "    if type(paths) is not list:\n",
    "        paths = [paths]\n",
    "    results = []\n",
    "    names = []\n",
    "    for path in paths:\n",
    "        results += [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "        names += [os.path.basename(os.path.dirname(y))+'_'+os.path.split(y)[1] for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return results,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## helper to speed things up by not uploading images if they already exist, can be overriden \n",
    "def check_exists(s3, bucket_name, stim_name):\n",
    "    try:\n",
    "        s3.Object(bucket_name,stim_name).load()    \n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:    \n",
    "        if (e.response['Error']['Code'] == \"404\"):\n",
    "            print('The object does not exist.')\n",
    "            return False\n",
    "        else:\n",
    "            print('Something else has gone wrong with {}'.format(stim_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass list of folders if there are stimuli in multiple folders. Make sure that the containing folder is informative, as the rest of the path is ignored in naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## provide a stem directory\n",
    "local_stem = 'XXX' #CHANGE THIS ⚡️\n",
    "dirnames = [d.split('/')[-1] for d in glob(local_stem+'/*')]\n",
    "paths_to_stim = [local_stem + d for d in dirnames]\n",
    "\n",
    "full_stim_paths, filenames = [x for x in list_files(paths_to_stim) if x !='.DS_Store'] #generate filenames and stimpaths\n",
    "full_map_paths, mapnames = [x for x in list_files(paths_to_stim, ext = 'png') if x !='.DS_Store'] #generate filenames and stimpaths for target/zone map\n",
    "full_hdf5_paths, hdf5names = [x for x in list_files(paths_to_stim, ext = 'hdf5') if x !='.DS_Store'] #generate filenames and stimpaths for hdf5\n",
    "print('We have {} stimuli to upload.'.format(len(full_stim_paths)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure to only up the _img pass\n",
    "full_stim_paths = [p for p in full_stim_paths if '_img' in p] \n",
    "filenames = [p for p in filenames if '_img' in p] \n",
    "print('We have {} stimuli to upload.'.format(len(full_stim_paths)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to S3. This expects the `.aws/credentials` file in your home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reallyRun = True\n",
    "upload_hdf5s = True\n",
    "if reallyRun:\n",
    "\n",
    "    ## establish connection to s3 \n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    ## create a bucket with the appropriate bucket name\n",
    "    try: \n",
    "        b = s3.create_bucket(Bucket=bucket_name) \n",
    "        print('Created new bucket.')\n",
    "#     except NoCredentialsError:\n",
    "#         print(\"Credential missing\") #.aws/credentials should be in home folder, not in repo folder\n",
    "    except Exception as e:\n",
    "        b = s3.Bucket(bucket_name)\n",
    "        print('Bucket already exists.',e)\n",
    "\n",
    "    ## do we want to overwrite files on s3?\n",
    "    overwrite = True\n",
    "    \n",
    "    ## set bucket and objects to public\n",
    "    b.Acl().put(ACL='public-read') ## sets bucket to public\n",
    "\n",
    "    ## now let's loop through stim paths and actually upload to s3 (woot!)\n",
    "    for i,path_to_file in enumerate(full_stim_paths):\n",
    "        stim_name = filenames[i]\n",
    "        if ((check_exists(s3, bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "            print('Now uploading {} as {} | {} of {}'.format(os.path.split(path_to_file)[-1],stim_name,(i+1),len(full_stim_paths)))\n",
    "            s3.Object(bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "            s3.Object(bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "        else: \n",
    "            print('Skipping {} | {} of {} because it already exists.'.format(os.path.split(path_to_file)[-1],(i+1),len(full_stim_paths)))\n",
    "        clear_output(wait=True)\n",
    "    print('Done uploading videos')\n",
    "    for i,path_to_file in enumerate(full_map_paths):\n",
    "        stim_name = mapnames[i]\n",
    "        if ((check_exists(s3, bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "            print('Now uploading {} as {} | {} of {}'.format(os.path.split(path_to_file)[-1],stim_name,(i+1),len(full_map_paths)))\n",
    "            s3.Object(bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "            s3.Object(bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "        else: \n",
    "            print('Skipping {} | {} of {} because it already exists.'.format(os.path.split(path_to_file)[-1],(i+1),len(full_map_paths)))\n",
    "        clear_output(wait=True)\n",
    "    print('Done uploading target/zone maps')\n",
    "    if upload_hdf5s:\n",
    "        for i,path_to_file in enumerate(full_hdf5_paths):\n",
    "            stim_name = hdf5names[i]\n",
    "            if ((check_exists(s3, bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "                print('Now uploading {} as {} | {} of {}'.format(os.path.split(path_to_file)[-1],stim_name,(i+1),len(full_hdf5_paths)))\n",
    "                s3.Object(bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "                s3.Object(bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "            else: \n",
    "                print('Skipping {} | {} of {} because it already exists.'.format(os.path.split(path_to_file)[-1],(i+1),len(full_hdf5_paths)))\n",
    "            clear_output(wait=True)\n",
    "    print('Done uploading hdf5s')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for my_bucket_object in b.objects.all():\n",
    "    print(my_bucket_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
