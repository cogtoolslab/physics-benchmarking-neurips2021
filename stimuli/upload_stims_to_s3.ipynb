{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload video stimuli to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which experiment? bucket_name is the name of the experiment and will be name of the databases both on mongoDB and S3\n",
    "# bucket_name = 'human-physics-benchmarking-dominoes-pilot' #dominoes\n",
    "#bucket_name = 'human-physics-benchmarking-towers-pilot' #towers\n",
    "bucket_name = 'human-physics-benchmarking-containment-pilot' #containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(paths, ext='mp4'):\n",
    "    \"\"\"Pass list of folders if there are stimuli in multiple folders. \n",
    "    Make sure that the containing folder is informative, as the rest of the path is ignored in naming. \n",
    "    Also returns filenames as uploaded to S3\"\"\"\n",
    "    if type(paths) is not list:\n",
    "        paths = [paths]\n",
    "    results = []\n",
    "    names = []\n",
    "    for path in paths:\n",
    "        results += [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "        names += [os.path.basename(os.path.dirname(y))+'_'+os.path.split(y)[1] for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return results,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper to speed things up by not uploading images if they already exist, can be overriden \n",
    "def check_exists(s3, bucket_name, stim_name):\n",
    "    try:\n",
    "        s3.Object(bucket_name,stim_name).load()    \n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:    \n",
    "        if (e.response['Error']['Code'] == \"404\"):\n",
    "            print('The object does not exist.')\n",
    "            return False\n",
    "        else:\n",
    "            print('Something else has gone wrong with {}'.format(stim_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass list of folders if there are stimuli in multiple folders. Make sure that the containing folder is informative, as the rest of the path is ignored in naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up paths, etc.\n",
    "# paths_to_stim = ['./example'] ## provide a list of full paths here.\n",
    "# paths_to_stim = [\n",
    "    \n",
    "#     # 3 domino trials\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_SJ025_boxroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_SJ025_tdwroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_default_boxroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_SJ020_d3_tdwroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_SJ020_o1flex_tdwroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_SJ020_d3chairs_o1plants_tdwroom/\",\n",
    "    \n",
    "#     # 0 domino trials\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_0mid_d3chairs_o1plants_tdwroom/\",\n",
    "    \n",
    "#     # 1 domino trials\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_1mid_J025R45_o1flex_tdwroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_1mid_J025R45_boxroom/\",\n",
    "    \n",
    "#     # 2 domino trials\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_2mid_J025R30_tdwroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_2mid_J020R15_d3chairs_o1plants_tdwroom/\",  \n",
    "    \n",
    "#     # \"Catch trials\" -- peoplen should be close to 100% \n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_4midRM1_tdwroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_4midRM1_boxroom/\",\n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_4mid_tdwroom/\",    \n",
    "#     \"/Users/dbear/neuroailab/physics_benchmarking/stimuli/pilot_dominoes_4mid_boxroom/\"\n",
    "    \n",
    "# ]\n",
    "\n",
    "# paths_to_stim = glob.glob()\n",
    "full_stim_paths, filenames = [x for x in list_files(paths_to_stim) if x !='.DS_Store'] #generate filenames and stimpaths\n",
    "print('We have {} stimuli to upload.'.format(len(full_stim_paths)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up paths, etc.\n",
    "# paths_to_stim = ['./example'] ## provide a list of full paths here.\n",
    "paths_to_stim = [\n",
    "    \n",
    "    # bowl containment\n",
    "    \"/Users/choldawa/Documents/Projects/tdw_physics/tdw_physics/target_controllers/stimuli/containment-bowl\",\n",
    "    # torus containment\n",
    "    \"/Users/choldawa/Documents/Projects/tdw_physics/tdw_physics/target_controllers/stimuli/containment-torus\",\n",
    "    # multi containment\n",
    "    \"/Users/choldawa/Documents/Projects/tdw_physics/tdw_physics/target_controllers/stimuli/containment-multi\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# paths_to_stim = glob.glob()\n",
    "full_stim_paths, filenames = [x for x in list_files(paths_to_stim) if x !='.DS_Store'] #generate filenames and stimpaths\n",
    "print('We have {} stimuli to upload.'.format(len(full_stim_paths))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_stem = '/Users/dbear/neuroailab/physics_benchmarking/stimuli/'\n",
    "dirnames = [d.split('/')[-1] for d in glob('./generation/pilot-towers/pilot_towers*')]\n",
    "paths_to_stim = [local_stem + d for d in dirnames]\n",
    "\n",
    "full_stim_paths, filenames = [x for x in list_files(paths_to_stim) if x !='.DS_Store'] #generate filenames and stimpaths\n",
    "print('We have {} stimuli to upload.'.format(len(full_stim_paths)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to S3. This expects the `.aws/credentials` file in your home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "\n",
    "    ## establish connection to s3 \n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    ## create a bucket with the appropriate bucket name\n",
    "    try: \n",
    "        b = s3.create_bucket(Bucket=bucket_name) \n",
    "        print('Created new bucket.')\n",
    "#     except NoCredentialsError:\n",
    "#         print(\"Credential missing\") #.aws/credentials should be in home folder, not in repo folder\n",
    "    except:\n",
    "        b = s3.Bucket(bucket_name)\n",
    "        print('Bucket already exists.')\n",
    "\n",
    "    ## do we want to overwrite files on s3?\n",
    "    overwrite = False\n",
    "    \n",
    "    ## set bucket and objects to public\n",
    "    b.Acl().put(ACL='public-read') ## sets bucket to public\n",
    "\n",
    "    ## now let's loop through stim paths and actually upload to s3 (woot!)\n",
    "    for i,path_to_file in enumerate(full_stim_paths):        # use sorted(full_stim_paths) when not using photodraw32\n",
    "        stim_name = filenames[i]\n",
    "        if ((check_exists(s3, bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "            print('Now uploading {} as {} | {} of {}'.format(os.path.split(path_to_file)[-1],stim_name,(i+1),len(full_stim_paths)))\n",
    "            s3.Object(bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "            s3.Object(bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "        else: \n",
    "            print('Skipping {} | {} of {} because it already exists.'.format(os.path.split(path_to_file)[-1],(i+1),len(full_stim_paths)))\n",
    "        clear_output(wait=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_bucket_object in b.objects.all():\n",
    "    print(my_bucket_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
